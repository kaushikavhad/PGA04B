{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linking to ImageMagick 6.9.9.14\n",
      "Enabled features: cairo, freetype, fftw, ghostscript, lcms, pango, rsvg, webp\n",
      "Disabled features: fontconfig, x11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting page 1 to svm_basic_1.png... done!\n",
      "Converting page 2 to svm_basic_2.png... done!\n",
      "Converting page 3 to svm_basic_3.png... done!\n",
      "Converting page 4 to svm_basic_4.png... done!\n",
      "Converting page 5 to svm_basic_5.png... done!\n",
      "Converting page 6 to svm_basic_6.png... done!\n",
      "Converting page 7 to svm_basic_7.png... done!\n",
      "Converting page 8 to svm_basic_8.png... done!\n",
      "Converting page 9 to svm_basic_9.png... done!\n",
      "Converting page 10 to svm_basic_10.png... done!\n",
      "Converting page 11 to svm_basic_11.png... done!\n",
      "Converting page 12 to svm_basic_12.png... done!\n",
      "Converting page 13 to svm_basic_13.png... done!\n",
      "Converting page 14 to svm_basic_14.png... done!\n",
      "Converting page 15 to svm_basic_15.png... done!\n",
      "Converting page 16 to svm_basic_16.png... done!\n",
      "Converting page 17 to svm_basic_17.png... done!\n",
      "Converting page 18 to svm_basic_18.png... done!\n",
      "Converting page 19 to svm_basic_19.png... done!\n",
      "Converting page 20 to svm_basic_20.png... done!\n",
      "Converting page 21 to svm_basic_21.png... done!\n",
      "Converting page 22 to svm_basic_22.png... done!\n",
      "Converting page 23 to svm_basic_23.png... done!\n",
      "Converting page 24 to svm_basic_24.png... done!\n",
      "Converting page 25 to svm_basic_25.png... done!\n",
      "Converting page 26 to svm_basic_26.png... done!\n",
      "Converting page 27 to svm_basic_27.png... done!\n",
      "Converting page 28 to svm_basic_28.png... done!\n"
     ]
    }
   ],
   "source": [
    "library(tesseract)\n",
    "library(magick)\n",
    "library(stringr)\n",
    "pdf_file <- pdftools::pdf_convert('M:\\\\Imarticus\\\\data sets\\\\Text mining\\\\svm_basic.pdf',\n",
    "                                 dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'Support Vector Machines:\\nTheory and Applications\\nLipo Wang\\n(ed.)\\n\\nSpringer, Berlin\\n2005\\n'</li>\n",
       "\t<li>'Preface\\n\\nThe support vector machine (SVM) is a supervised learning method that\\ngenerates input-output mapping functions from a set of labeled training data.\\nThe mapping function can be either a classification function, i.e., the cate-\\ngory of the input data, or a regression function. For classification, nonlinear\\nkernel functions are often used to transform input data to a high-dimensional\\nfeature space in which the input data become more separable compared to\\nthe original input space. Maximum-margin hyperplanes are then created. ‘The\\nmodel thus produced depends on only a subset of the training data near the\\nclass boundaries. Similarly, the model produced by Support Vector Regres-\\nsion ignores any training data that is sufficiently close to the model prediction.\\nSVMs are also said to belong to “kernel methods”.\\n\\nIn addition to its solid mathematical foundation in statistical learning\\ntheory, SVMs have demonstrated highly competitive performance in numerous\\nreal-world applications, such as bioinformatics, text mining, face recognition,\\nand image processing, which has established SVMs as one of the state-of-\\nthe-art tools for machine learning and data mining, along with other soft\\ncomputing techniques, e.g., neural networks and fuzzy systems.\\n\\nThis volume is composed of 20 chapters selected from the recent myriad\\nof novel SVM applications, powerful SVM algorithms, as well as enlighten-\\ning theoretical analysis. Written by experts in their respective fields, the first\\n12 chapters concentrate on SVM theory, whereas the subsequent 8 chapters\\nemphasize practical applications, although the “decision boundary” separat-\\ning these two categories is rather “fuzzy”.\\n\\nKecman first presents an introduction on the SVM, explaining the basic\\ntheory and implementation aspects. In the chapter contributed by Ma and\\nCherkassky, a novel approach to nonlinear classification using a collection of\\nseveral simple (linear) classifiers is proposed based on a new formulation of\\nthe learning problem called multiple model estimation. Pelckmans, Goethals,\\nDe Brabanter, Suykens, and De Moor describe componentwise Least Squares\\nSupport Vector Machines (LS-SVMs) for the estimation of additive models\\nconsisting of a sum of nonlinear components.\\n'</li>\n",
       "\t<li>'VI Preface\\n\\nMotivated by the statistical query model, Mitra, Murthy and Pal study an\\nactive learning strategy to solve the large quadratic programming problem of\\nSVM design in data mining applications. Kaizhu Huang, Haiqin Yang, King,\\nand Lyu propose a unifying theory of the Maxi-Min Margin Machine (M4)\\nthat subsumes the SVM, the minimax probability machine, and the linear\\ndiscriminant analysis. Vogt and Kecman present an active-set algorithm for\\nquadratic programming problems in SVMs, as an alternative to working-set\\n(decomposition) techniques, especially when the data set is not too large, the\\nproblem is ill-conditioned, or when high precision is needed.\\n\\nBeing aware of the abundance of methods for SVM model selection,\\nAnguita, Boni, Ridella, Rivieccio, and Sterpi carefully analyze the most well-\\nknown methods and test some of them on standard benchmarks to evaluate\\ntheir effectiveness. In an attempt to minimize bias, Peng, Heisterkamp, and\\nDai propose locally adaptive nearest neighbor classification methods by using\\nlocally linear SVMs and quasiconformal transformed kernels. Williams, Wu,\\nand Feng discuss two geometric methods to improve SVM performance, i.e.,\\n(1) adapting kernels by magnifying the Riemannian metric in the neighbor-\\nhood of the boundary, thereby increasing class separation, and (2) optimally\\nlocating the separating boundary, given that the distributions of data on either\\nside may have different scales.\\n\\nSong, Hu, and Xulei Yang derive a Kuhn-Tucker condition and a decom-\\nposition algorithm for robust SVMs to deal with overfitting in the presence of\\noutliers. Lin and Sheng-de Wang design a fuzzy SVM with automatic deter-\\nmination of the membership functions. Kecman, Te-Ming Huang, and Vogt\\npresent the latest developments and results of the Iterative Single Data Algo-\\nrithm for solving large-scale problems.\\n\\nExploiting regularization and subspace decomposition techniques, Lu,\\nPlataniotis, and Venetsanopoulos introduce a new kernel discriminant learn-\\ning method and apply the method to face recognition. Kwang In Kim, Jung,\\nand Hang Joon Kim employ SVMs and neural networks for automobile li-\\ncense plate localization, by classifying each pixel in the image into the object\\nof interest or the background based on localized color texture patterns. Mat-\\ntera discusses SVM applications in signal processing, especially the problem\\nof digital channel equalization. Chu, Jin, and Lipo Wang use SVMs to solve\\ntwo important problems in bioinformatics, i.e., cancer diagnosis based on mi-\\ncroarray gene expression data and protein secondary structure prediction.\\n\\nEmulating the natural nose, Brezmes, Llobet, Al-Khalifa, Maldonado, and\\nGardner describe how SVMs are being evaluated in the gas sensor commu-\\nnity to discriminate different blends of coffee, different types of vapors and\\nnerve agents. Zhan presents an application of the SVM in inverse problems\\nin ocean color remote sensing. Liang uses SVMs for non-invasive diagnosis\\nof delayed gastric emptying from the cutaneous electrogastrograms (EGGs).\\nRojo-Alvarez, Garcia-Alberola, Artés-Rodriguez, and Arenal-Maiz apply\\nSVMs, together with bootstrap resampling and principal component analysis,\\nto tachycardia discrimination in implantable cardioverter defibrillators.\\n'</li>\n",
       "\t<li>'Preface Vil\\nI would like to express my sincere appreciation to all authors and reviewers\\nwho have spent their precious time and efforts in making this book a reality.\\nI wish to especially thank Professor Vojislav Kecman, who graciously took\\non the enormous task of writing a comprehensive introductory chapter, in\\naddition to his other great contributions to this book. My gratitude also goes\\nto Professor Janusz Kacprzyk and Dr. Thomas Ditzinger for their kindest\\nsupport and help with this book.\\nSingapore Lipo Wang\\nJanuary 2005\\n'</li>\n",
       "\t<li>''</li>\n",
       "\t<li>'Contents\\n\\nSupport Vector Machines — An Introduction\\n\\nV. K€CMGN. 6. eee eee eee eee eeeeeee\\nMultiple Model Estimation\\n\\nfor Nonlinear Classification\\n\\nY. Ma and V. Cherkassky .. 0.0.00. AY\\nComponentwise Least Squares Support Vector Machines\\n\\nKk. Pelckmans, I. Goethals, J. De Brabanter, J.A.K. Suykens, and B.\\n\\nDe MOor .. ccc nee eee eee eee TT\\nActive Support Vector Learning with Statistical Queries\\n\\nP. Mitra, C.A. Murthy, and SK. Pal... eee ee ID\\nLocal Learning vs. Global Learning: An Introduction\\n\\nto Maxi-Min Margin Machine\\n\\nKk. Huang, H. Yang, I. King, and M.R. Lyu ..... eee eee ee ee L18\\nActive-Set Methods for Support Vector Machines\\n\\nM. Vogt and V. Kecman ... 6... cece ee eee ee A 138\\nTheoretical and Practical Model Selection Methods\\n\\nfor Support Vector Classifiers\\n\\nD. Anguita, A. Boni, S. Ridella, FP. Rivieccio, and D. Sterpi...........159\\nAdaptive Discriminant\\n\\nand Quasiconformal Kernel Nearest Neighbor Classification\\n\\nJ. Peng, D.R. Heisterkamp, and H.K. Dat .. 1... ee ee LB\\nImproving the Performance of the Support Vector Machine:\\n\\nTwo Geometrical Scaling Methods\\n\\nP. Williams, S. Wu, and J. Feng 0.0... ccc cee eee ee 205\\n'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Support Vector Machines:\\textbackslash{}nTheory and Applications\\textbackslash{}nLipo Wang\\textbackslash{}n(ed.)\\textbackslash{}n\\textbackslash{}nSpringer, Berlin\\textbackslash{}n2005\\textbackslash{}n'\n",
       "\\item 'Preface\\textbackslash{}n\\textbackslash{}nThe support vector machine (SVM) is a supervised learning method that\\textbackslash{}ngenerates input-output mapping functions from a set of labeled training data.\\textbackslash{}nThe mapping function can be either a classification function, i.e., the cate-\\textbackslash{}ngory of the input data, or a regression function. For classification, nonlinear\\textbackslash{}nkernel functions are often used to transform input data to a high-dimensional\\textbackslash{}nfeature space in which the input data become more separable compared to\\textbackslash{}nthe original input space. Maximum-margin hyperplanes are then created. ‘The\\textbackslash{}nmodel thus produced depends on only a subset of the training data near the\\textbackslash{}nclass boundaries. Similarly, the model produced by Support Vector Regres-\\textbackslash{}nsion ignores any training data that is sufficiently close to the model prediction.\\textbackslash{}nSVMs are also said to belong to “kernel methods”.\\textbackslash{}n\\textbackslash{}nIn addition to its solid mathematical foundation in statistical learning\\textbackslash{}ntheory, SVMs have demonstrated highly competitive performance in numerous\\textbackslash{}nreal-world applications, such as bioinformatics, text mining, face recognition,\\textbackslash{}nand image processing, which has established SVMs as one of the state-of-\\textbackslash{}nthe-art tools for machine learning and data mining, along with other soft\\textbackslash{}ncomputing techniques, e.g., neural networks and fuzzy systems.\\textbackslash{}n\\textbackslash{}nThis volume is composed of 20 chapters selected from the recent myriad\\textbackslash{}nof novel SVM applications, powerful SVM algorithms, as well as enlighten-\\textbackslash{}ning theoretical analysis. Written by experts in their respective fields, the first\\textbackslash{}n12 chapters concentrate on SVM theory, whereas the subsequent 8 chapters\\textbackslash{}nemphasize practical applications, although the “decision boundary” separat-\\textbackslash{}ning these two categories is rather “fuzzy”.\\textbackslash{}n\\textbackslash{}nKecman first presents an introduction on the SVM, explaining the basic\\textbackslash{}ntheory and implementation aspects. In the chapter contributed by Ma and\\textbackslash{}nCherkassky, a novel approach to nonlinear classification using a collection of\\textbackslash{}nseveral simple (linear) classifiers is proposed based on a new formulation of\\textbackslash{}nthe learning problem called multiple model estimation. Pelckmans, Goethals,\\textbackslash{}nDe Brabanter, Suykens, and De Moor describe componentwise Least Squares\\textbackslash{}nSupport Vector Machines (LS-SVMs) for the estimation of additive models\\textbackslash{}nconsisting of a sum of nonlinear components.\\textbackslash{}n'\n",
       "\\item 'VI Preface\\textbackslash{}n\\textbackslash{}nMotivated by the statistical query model, Mitra, Murthy and Pal study an\\textbackslash{}nactive learning strategy to solve the large quadratic programming problem of\\textbackslash{}nSVM design in data mining applications. Kaizhu Huang, Haiqin Yang, King,\\textbackslash{}nand Lyu propose a unifying theory of the Maxi-Min Margin Machine (M4)\\textbackslash{}nthat subsumes the SVM, the minimax probability machine, and the linear\\textbackslash{}ndiscriminant analysis. Vogt and Kecman present an active-set algorithm for\\textbackslash{}nquadratic programming problems in SVMs, as an alternative to working-set\\textbackslash{}n(decomposition) techniques, especially when the data set is not too large, the\\textbackslash{}nproblem is ill-conditioned, or when high precision is needed.\\textbackslash{}n\\textbackslash{}nBeing aware of the abundance of methods for SVM model selection,\\textbackslash{}nAnguita, Boni, Ridella, Rivieccio, and Sterpi carefully analyze the most well-\\textbackslash{}nknown methods and test some of them on standard benchmarks to evaluate\\textbackslash{}ntheir effectiveness. In an attempt to minimize bias, Peng, Heisterkamp, and\\textbackslash{}nDai propose locally adaptive nearest neighbor classification methods by using\\textbackslash{}nlocally linear SVMs and quasiconformal transformed kernels. Williams, Wu,\\textbackslash{}nand Feng discuss two geometric methods to improve SVM performance, i.e.,\\textbackslash{}n(1) adapting kernels by magnifying the Riemannian metric in the neighbor-\\textbackslash{}nhood of the boundary, thereby increasing class separation, and (2) optimally\\textbackslash{}nlocating the separating boundary, given that the distributions of data on either\\textbackslash{}nside may have different scales.\\textbackslash{}n\\textbackslash{}nSong, Hu, and Xulei Yang derive a Kuhn-Tucker condition and a decom-\\textbackslash{}nposition algorithm for robust SVMs to deal with overfitting in the presence of\\textbackslash{}noutliers. Lin and Sheng-de Wang design a fuzzy SVM with automatic deter-\\textbackslash{}nmination of the membership functions. Kecman, Te-Ming Huang, and Vogt\\textbackslash{}npresent the latest developments and results of the Iterative Single Data Algo-\\textbackslash{}nrithm for solving large-scale problems.\\textbackslash{}n\\textbackslash{}nExploiting regularization and subspace decomposition techniques, Lu,\\textbackslash{}nPlataniotis, and Venetsanopoulos introduce a new kernel discriminant learn-\\textbackslash{}ning method and apply the method to face recognition. Kwang In Kim, Jung,\\textbackslash{}nand Hang Joon Kim employ SVMs and neural networks for automobile li-\\textbackslash{}ncense plate localization, by classifying each pixel in the image into the object\\textbackslash{}nof interest or the background based on localized color texture patterns. Mat-\\textbackslash{}ntera discusses SVM applications in signal processing, especially the problem\\textbackslash{}nof digital channel equalization. Chu, Jin, and Lipo Wang use SVMs to solve\\textbackslash{}ntwo important problems in bioinformatics, i.e., cancer diagnosis based on mi-\\textbackslash{}ncroarray gene expression data and protein secondary structure prediction.\\textbackslash{}n\\textbackslash{}nEmulating the natural nose, Brezmes, Llobet, Al-Khalifa, Maldonado, and\\textbackslash{}nGardner describe how SVMs are being evaluated in the gas sensor commu-\\textbackslash{}nnity to discriminate different blends of coffee, different types of vapors and\\textbackslash{}nnerve agents. Zhan presents an application of the SVM in inverse problems\\textbackslash{}nin ocean color remote sensing. Liang uses SVMs for non-invasive diagnosis\\textbackslash{}nof delayed gastric emptying from the cutaneous electrogastrograms (EGGs).\\textbackslash{}nRojo-Alvarez, Garcia-Alberola, Artés-Rodriguez, and Arenal-Maiz apply\\textbackslash{}nSVMs, together with bootstrap resampling and principal component analysis,\\textbackslash{}nto tachycardia discrimination in implantable cardioverter defibrillators.\\textbackslash{}n'\n",
       "\\item 'Preface Vil\\textbackslash{}nI would like to express my sincere appreciation to all authors and reviewers\\textbackslash{}nwho have spent their precious time and efforts in making this book a reality.\\textbackslash{}nI wish to especially thank Professor Vojislav Kecman, who graciously took\\textbackslash{}non the enormous task of writing a comprehensive introductory chapter, in\\textbackslash{}naddition to his other great contributions to this book. My gratitude also goes\\textbackslash{}nto Professor Janusz Kacprzyk and Dr. Thomas Ditzinger for their kindest\\textbackslash{}nsupport and help with this book.\\textbackslash{}nSingapore Lipo Wang\\textbackslash{}nJanuary 2005\\textbackslash{}n'\n",
       "\\item ''\n",
       "\\item 'Contents\\textbackslash{}n\\textbackslash{}nSupport Vector Machines — An Introduction\\textbackslash{}n\\textbackslash{}nV. K€CMGN. 6. eee eee eee eee eeeeeee\\textbackslash{}nMultiple Model Estimation\\textbackslash{}n\\textbackslash{}nfor Nonlinear Classification\\textbackslash{}n\\textbackslash{}nY. Ma and V. Cherkassky .. 0.0.00. AY\\textbackslash{}nComponentwise Least Squares Support Vector Machines\\textbackslash{}n\\textbackslash{}nKk. Pelckmans, I. Goethals, J. De Brabanter, J.A.K. Suykens, and B.\\textbackslash{}n\\textbackslash{}nDe MOor .. ccc nee eee eee eee TT\\textbackslash{}nActive Support Vector Learning with Statistical Queries\\textbackslash{}n\\textbackslash{}nP. Mitra, C.A. Murthy, and SK. Pal... eee ee ID\\textbackslash{}nLocal Learning vs. Global Learning: An Introduction\\textbackslash{}n\\textbackslash{}nto Maxi-Min Margin Machine\\textbackslash{}n\\textbackslash{}nKk. Huang, H. Yang, I. King, and M.R. Lyu ..... eee eee ee ee L18\\textbackslash{}nActive-Set Methods for Support Vector Machines\\textbackslash{}n\\textbackslash{}nM. Vogt and V. Kecman ... 6... cece ee eee ee A 138\\textbackslash{}nTheoretical and Practical Model Selection Methods\\textbackslash{}n\\textbackslash{}nfor Support Vector Classifiers\\textbackslash{}n\\textbackslash{}nD. Anguita, A. Boni, S. Ridella, FP. Rivieccio, and D. Sterpi...........159\\textbackslash{}nAdaptive Discriminant\\textbackslash{}n\\textbackslash{}nand Quasiconformal Kernel Nearest Neighbor Classification\\textbackslash{}n\\textbackslash{}nJ. Peng, D.R. Heisterkamp, and H.K. Dat .. 1... ee ee LB\\textbackslash{}nImproving the Performance of the Support Vector Machine:\\textbackslash{}n\\textbackslash{}nTwo Geometrical Scaling Methods\\textbackslash{}n\\textbackslash{}nP. Williams, S. Wu, and J. Feng 0.0... ccc cee eee ee 205\\textbackslash{}n'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Support Vector Machines:\\nTheory and Applications\\nLipo Wang\\n(ed.)\\n\\nSpringer, Berlin\\n2005\\n'\n",
       "2. 'Preface\\n\\nThe support vector machine (SVM) is a supervised learning method that\\ngenerates input-output mapping functions from a set of labeled training data.\\nThe mapping function can be either a classification function, i.e., the cate-\\ngory of the input data, or a regression function. For classification, nonlinear\\nkernel functions are often used to transform input data to a high-dimensional\\nfeature space in which the input data become more separable compared to\\nthe original input space. Maximum-margin hyperplanes are then created. ‘The\\nmodel thus produced depends on only a subset of the training data near the\\nclass boundaries. Similarly, the model produced by Support Vector Regres-\\nsion ignores any training data that is sufficiently close to the model prediction.\\nSVMs are also said to belong to “kernel methods”.\\n\\nIn addition to its solid mathematical foundation in statistical learning\\ntheory, SVMs have demonstrated highly competitive performance in numerous\\nreal-world applications, such as bioinformatics, text mining, face recognition,\\nand image processing, which has established SVMs as one of the state-of-\\nthe-art tools for machine learning and data mining, along with other soft\\ncomputing techniques, e.g., neural networks and fuzzy systems.\\n\\nThis volume is composed of 20 chapters selected from the recent myriad\\nof novel SVM applications, powerful SVM algorithms, as well as enlighten-\\ning theoretical analysis. Written by experts in their respective fields, the first\\n12 chapters concentrate on SVM theory, whereas the subsequent 8 chapters\\nemphasize practical applications, although the “decision boundary” separat-\\ning these two categories is rather “fuzzy”.\\n\\nKecman first presents an introduction on the SVM, explaining the basic\\ntheory and implementation aspects. In the chapter contributed by Ma and\\nCherkassky, a novel approach to nonlinear classification using a collection of\\nseveral simple (linear) classifiers is proposed based on a new formulation of\\nthe learning problem called multiple model estimation. Pelckmans, Goethals,\\nDe Brabanter, Suykens, and De Moor describe componentwise Least Squares\\nSupport Vector Machines (LS-SVMs) for the estimation of additive models\\nconsisting of a sum of nonlinear components.\\n'\n",
       "3. 'VI Preface\\n\\nMotivated by the statistical query model, Mitra, Murthy and Pal study an\\nactive learning strategy to solve the large quadratic programming problem of\\nSVM design in data mining applications. Kaizhu Huang, Haiqin Yang, King,\\nand Lyu propose a unifying theory of the Maxi-Min Margin Machine (M4)\\nthat subsumes the SVM, the minimax probability machine, and the linear\\ndiscriminant analysis. Vogt and Kecman present an active-set algorithm for\\nquadratic programming problems in SVMs, as an alternative to working-set\\n(decomposition) techniques, especially when the data set is not too large, the\\nproblem is ill-conditioned, or when high precision is needed.\\n\\nBeing aware of the abundance of methods for SVM model selection,\\nAnguita, Boni, Ridella, Rivieccio, and Sterpi carefully analyze the most well-\\nknown methods and test some of them on standard benchmarks to evaluate\\ntheir effectiveness. In an attempt to minimize bias, Peng, Heisterkamp, and\\nDai propose locally adaptive nearest neighbor classification methods by using\\nlocally linear SVMs and quasiconformal transformed kernels. Williams, Wu,\\nand Feng discuss two geometric methods to improve SVM performance, i.e.,\\n(1) adapting kernels by magnifying the Riemannian metric in the neighbor-\\nhood of the boundary, thereby increasing class separation, and (2) optimally\\nlocating the separating boundary, given that the distributions of data on either\\nside may have different scales.\\n\\nSong, Hu, and Xulei Yang derive a Kuhn-Tucker condition and a decom-\\nposition algorithm for robust SVMs to deal with overfitting in the presence of\\noutliers. Lin and Sheng-de Wang design a fuzzy SVM with automatic deter-\\nmination of the membership functions. Kecman, Te-Ming Huang, and Vogt\\npresent the latest developments and results of the Iterative Single Data Algo-\\nrithm for solving large-scale problems.\\n\\nExploiting regularization and subspace decomposition techniques, Lu,\\nPlataniotis, and Venetsanopoulos introduce a new kernel discriminant learn-\\ning method and apply the method to face recognition. Kwang In Kim, Jung,\\nand Hang Joon Kim employ SVMs and neural networks for automobile li-\\ncense plate localization, by classifying each pixel in the image into the object\\nof interest or the background based on localized color texture patterns. Mat-\\ntera discusses SVM applications in signal processing, especially the problem\\nof digital channel equalization. Chu, Jin, and Lipo Wang use SVMs to solve\\ntwo important problems in bioinformatics, i.e., cancer diagnosis based on mi-\\ncroarray gene expression data and protein secondary structure prediction.\\n\\nEmulating the natural nose, Brezmes, Llobet, Al-Khalifa, Maldonado, and\\nGardner describe how SVMs are being evaluated in the gas sensor commu-\\nnity to discriminate different blends of coffee, different types of vapors and\\nnerve agents. Zhan presents an application of the SVM in inverse problems\\nin ocean color remote sensing. Liang uses SVMs for non-invasive diagnosis\\nof delayed gastric emptying from the cutaneous electrogastrograms (EGGs).\\nRojo-Alvarez, Garcia-Alberola, Artés-Rodriguez, and Arenal-Maiz apply\\nSVMs, together with bootstrap resampling and principal component analysis,\\nto tachycardia discrimination in implantable cardioverter defibrillators.\\n'\n",
       "4. 'Preface Vil\\nI would like to express my sincere appreciation to all authors and reviewers\\nwho have spent their precious time and efforts in making this book a reality.\\nI wish to especially thank Professor Vojislav Kecman, who graciously took\\non the enormous task of writing a comprehensive introductory chapter, in\\naddition to his other great contributions to this book. My gratitude also goes\\nto Professor Janusz Kacprzyk and Dr. Thomas Ditzinger for their kindest\\nsupport and help with this book.\\nSingapore Lipo Wang\\nJanuary 2005\\n'\n",
       "5. ''\n",
       "6. 'Contents\\n\\nSupport Vector Machines — An Introduction\\n\\nV. K€CMGN. 6. eee eee eee eee eeeeeee\\nMultiple Model Estimation\\n\\nfor Nonlinear Classification\\n\\nY. Ma and V. Cherkassky .. 0.0.00. AY\\nComponentwise Least Squares Support Vector Machines\\n\\nKk. Pelckmans, I. Goethals, J. De Brabanter, J.A.K. Suykens, and B.\\n\\nDe MOor .. ccc nee eee eee eee TT\\nActive Support Vector Learning with Statistical Queries\\n\\nP. Mitra, C.A. Murthy, and SK. Pal... eee ee ID\\nLocal Learning vs. Global Learning: An Introduction\\n\\nto Maxi-Min Margin Machine\\n\\nKk. Huang, H. Yang, I. King, and M.R. Lyu ..... eee eee ee ee L18\\nActive-Set Methods for Support Vector Machines\\n\\nM. Vogt and V. Kecman ... 6... cece ee eee ee A 138\\nTheoretical and Practical Model Selection Methods\\n\\nfor Support Vector Classifiers\\n\\nD. Anguita, A. Boni, S. Ridella, FP. Rivieccio, and D. Sterpi...........159\\nAdaptive Discriminant\\n\\nand Quasiconformal Kernel Nearest Neighbor Classification\\n\\nJ. Peng, D.R. Heisterkamp, and H.K. Dat .. 1... ee ee LB\\nImproving the Performance of the Support Vector Machine:\\n\\nTwo Geometrical Scaling Methods\\n\\nP. Williams, S. Wu, and J. Feng 0.0... ccc cee eee ee 205\\n'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"Support Vector Machines:\\nTheory and Applications\\nLipo Wang\\n(ed.)\\n\\nSpringer, Berlin\\n2005\\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
       "[2] \"Preface\\n\\nThe support vector machine (SVM) is a supervised learning method that\\ngenerates input-output mapping functions from a set of labeled training data.\\nThe mapping function can be either a classification function, i.e., the cate-\\ngory of the input data, or a regression function. For classification, nonlinear\\nkernel functions are often used to transform input data to a high-dimensional\\nfeature space in which the input data become more separable compared to\\nthe original input space. Maximum-margin hyperplanes are then created. ‘The\\nmodel thus produced depends on only a subset of the training data near the\\nclass boundaries. Similarly, the model produced by Support Vector Regres-\\nsion ignores any training data that is sufficiently close to the model prediction.\\nSVMs are also said to belong to “kernel methods”.\\n\\nIn addition to its solid mathematical foundation in statistical learning\\ntheory, SVMs have demonstrated highly competitive performance in numerous\\nreal-world applications, such as bioinformatics, text mining, face recognition,\\nand image processing, which has established SVMs as one of the state-of-\\nthe-art tools for machine learning and data mining, along with other soft\\ncomputing techniques, e.g., neural networks and fuzzy systems.\\n\\nThis volume is composed of 20 chapters selected from the recent myriad\\nof novel SVM applications, powerful SVM algorithms, as well as enlighten-\\ning theoretical analysis. Written by experts in their respective fields, the first\\n12 chapters concentrate on SVM theory, whereas the subsequent 8 chapters\\nemphasize practical applications, although the “decision boundary” separat-\\ning these two categories is rather “fuzzy”.\\n\\nKecman first presents an introduction on the SVM, explaining the basic\\ntheory and implementation aspects. In the chapter contributed by Ma and\\nCherkassky, a novel approach to nonlinear classification using a collection of\\nseveral simple (linear) classifiers is proposed based on a new formulation of\\nthe learning problem called multiple model estimation. Pelckmans, Goethals,\\nDe Brabanter, Suykens, and De Moor describe componentwise Least Squares\\nSupport Vector Machines (LS-SVMs) for the estimation of additive models\\nconsisting of a sum of nonlinear components.\\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "[3] \"VI Preface\\n\\nMotivated by the statistical query model, Mitra, Murthy and Pal study an\\nactive learning strategy to solve the large quadratic programming problem of\\nSVM design in data mining applications. Kaizhu Huang, Haiqin Yang, King,\\nand Lyu propose a unifying theory of the Maxi-Min Margin Machine (M4)\\nthat subsumes the SVM, the minimax probability machine, and the linear\\ndiscriminant analysis. Vogt and Kecman present an active-set algorithm for\\nquadratic programming problems in SVMs, as an alternative to working-set\\n(decomposition) techniques, especially when the data set is not too large, the\\nproblem is ill-conditioned, or when high precision is needed.\\n\\nBeing aware of the abundance of methods for SVM model selection,\\nAnguita, Boni, Ridella, Rivieccio, and Sterpi carefully analyze the most well-\\nknown methods and test some of them on standard benchmarks to evaluate\\ntheir effectiveness. In an attempt to minimize bias, Peng, Heisterkamp, and\\nDai propose locally adaptive nearest neighbor classification methods by using\\nlocally linear SVMs and quasiconformal transformed kernels. Williams, Wu,\\nand Feng discuss two geometric methods to improve SVM performance, i.e.,\\n(1) adapting kernels by magnifying the Riemannian metric in the neighbor-\\nhood of the boundary, thereby increasing class separation, and (2) optimally\\nlocating the separating boundary, given that the distributions of data on either\\nside may have different scales.\\n\\nSong, Hu, and Xulei Yang derive a Kuhn-Tucker condition and a decom-\\nposition algorithm for robust SVMs to deal with overfitting in the presence of\\noutliers. Lin and Sheng-de Wang design a fuzzy SVM with automatic deter-\\nmination of the membership functions. Kecman, Te-Ming Huang, and Vogt\\npresent the latest developments and results of the Iterative Single Data Algo-\\nrithm for solving large-scale problems.\\n\\nExploiting regularization and subspace decomposition techniques, Lu,\\nPlataniotis, and Venetsanopoulos introduce a new kernel discriminant learn-\\ning method and apply the method to face recognition. Kwang In Kim, Jung,\\nand Hang Joon Kim employ SVMs and neural networks for automobile li-\\ncense plate localization, by classifying each pixel in the image into the object\\nof interest or the background based on localized color texture patterns. Mat-\\ntera discusses SVM applications in signal processing, especially the problem\\nof digital channel equalization. Chu, Jin, and Lipo Wang use SVMs to solve\\ntwo important problems in bioinformatics, i.e., cancer diagnosis based on mi-\\ncroarray gene expression data and protein secondary structure prediction.\\n\\nEmulating the natural nose, Brezmes, Llobet, Al-Khalifa, Maldonado, and\\nGardner describe how SVMs are being evaluated in the gas sensor commu-\\nnity to discriminate different blends of coffee, different types of vapors and\\nnerve agents. Zhan presents an application of the SVM in inverse problems\\nin ocean color remote sensing. Liang uses SVMs for non-invasive diagnosis\\nof delayed gastric emptying from the cutaneous electrogastrograms (EGGs).\\nRojo-Alvarez, Garcia-Alberola, Artés-Rodriguez, and Arenal-Maiz apply\\nSVMs, together with bootstrap resampling and principal component analysis,\\nto tachycardia discrimination in implantable cardioverter defibrillators.\\n\"\n",
       "[4] \"Preface Vil\\nI would like to express my sincere appreciation to all authors and reviewers\\nwho have spent their precious time and efforts in making this book a reality.\\nI wish to especially thank Professor Vojislav Kecman, who graciously took\\non the enormous task of writing a comprehensive introductory chapter, in\\naddition to his other great contributions to this book. My gratitude also goes\\nto Professor Janusz Kacprzyk and Dr. Thomas Ditzinger for their kindest\\nsupport and help with this book.\\nSingapore Lipo Wang\\nJanuary 2005\\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "[5] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           \n",
       "[6] \"Contents\\n\\nSupport Vector Machines — An Introduction\\n\\nV. K\\200CMGN. 6. eee eee eee eee eeeeeee\\nMultiple Model Estimation\\n\\nfor Nonlinear Classification\\n\\nY. Ma and V. Cherkassky .. 0.0.00. AY\\nComponentwise Least Squares Support Vector Machines\\n\\nKk. Pelckmans, I. Goethals, J. De Brabanter, J.A.K. Suykens, and B.\\n\\nDe MOor .. ccc nee eee eee eee TT\\nActive Support Vector Learning with Statistical Queries\\n\\nP. Mitra, C.A. Murthy, and SK. Pal... eee ee ID\\nLocal Learning vs. Global Learning: An Introduction\\n\\nto Maxi-Min Margin Machine\\n\\nKk. Huang, H. Yang, I. King, and M.R. Lyu ..... eee eee ee ee L18\\nActive-Set Methods for Support Vector Machines\\n\\nM. Vogt and V. Kecman ... 6... cece ee eee ee A 138\\nTheoretical and Practical Model Selection Methods\\n\\nfor Support Vector Classifiers\\n\\nD. Anguita, A. Boni, S. Ridella, FP. Rivieccio, and D. Sterpi...........159\\nAdaptive Discriminant\\n\\nand Quasiconformal Kernel Nearest Neighbor Classification\\n\\nJ. Peng, D.R. Heisterkamp, and H.K. Dat .. 1... ee ee LB\\nImproving the Performance of the Support Vector Machine:\\n\\nTwo Geometrical Scaling Methods\\n\\nP. Williams, S. Wu, and J. Feng 0.0... ccc cee eee ee 205\\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text<- tesseract::ocr(pdf_file)\n",
    "head(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'Support\\nVector\\nMachines:\\nTheory\\nand\\nApplications\\nLipo\\nWang\\n(ed.)\\n\\nSpringer,\\nBerlin\\n2005\\n'</li>\n",
       "\t<li>'Preface\\n\\nThe\\nsupport\\nvector\\nmachine\\n(SVM)\\nis\\na\\nsupervised\\nlearning\\nmethod\\nthat\\ngenerates\\ninput-output\\nmapping\\nfunctions\\nfrom\\na\\nset\\nof\\nlabeled\\ntraining\\ndata.\\nThe\\nmapping\\nfunction\\ncan\\nbe\\neither\\na\\nclassification\\nfunction,\\ni.e.,\\nthe\\ncate-\\ngory\\nof\\nthe\\ninput\\ndata,\\nor\\na\\nregression\\nfunction.\\nFor\\nclassification,\\nnonlinear\\nkernel\\nfunctions\\nare\\noften\\nused\\nto\\ntransform\\ninput\\ndata\\nto\\na\\nhigh-dimensional\\nfeature\\nspace\\nin\\nwhich\\nthe\\ninput\\ndata\\nbecome\\nmore\\nseparable\\ncompared\\nto\\nthe\\noriginal\\ninput\\nspace.\\nMaximum-margin\\nhyperplanes\\nare\\nthen\\ncreated.\\n‘The\\nmodel\\nthus\\nproduced\\ndepends\\non\\nonly\\na\\nsubset\\nof\\nthe\\ntraining\\ndata\\nnear\\nthe\\nclass\\nboundaries.\\nSimilarly,\\nthe\\nmodel\\nproduced\\nby\\nSupport\\nVector\\nRegres-\\nsion\\nignores\\nany\\ntraining\\ndata\\nthat\\nis\\nsufficiently\\nclose\\nto\\nthe\\nmodel\\nprediction.\\nSVMs\\nare\\nalso\\nsaid\\nto\\nbelong\\nto\\n“kernel\\nmethods”.\\n\\nIn\\naddition\\nto\\nits\\nsolid\\nmathematical\\nfoundation\\nin\\nstatistical\\nlearning\\ntheory,\\nSVMs\\nhave\\ndemonstrated\\nhighly\\ncompetitive\\nperformance\\nin\\nnumerous\\nreal-world\\napplications,\\nsuch\\nas\\nbioinformatics,\\ntext\\nmining,\\nface\\nrecognition,\\nand\\nimage\\nprocessing,\\nwhich\\nhas\\nestablished\\nSVMs\\nas\\none\\nof\\nthe\\nstate-of-\\nthe-art\\ntools\\nfor\\nmachine\\nlearning\\nand\\ndata\\nmining,\\nalong\\nwith\\nother\\nsoft\\ncomputing\\ntechniques,\\ne.g.,\\nneural\\nnetworks\\nand\\nfuzzy\\nsystems.\\n\\nThis\\nvolume\\nis\\ncomposed\\nof\\n20\\nchapters\\nselected\\nfrom\\nthe\\nrecent\\nmyriad\\nof\\nnovel\\nSVM\\napplications,\\npowerful\\nSVM\\nalgorithms,\\nas\\nwell\\nas\\nenlighten-\\ning\\ntheoretical\\nanalysis.\\nWritten\\nby\\nexperts\\nin\\ntheir\\nrespective\\nfields,\\nthe\\nfirst\\n12\\nchapters\\nconcentrate\\non\\nSVM\\ntheory,\\nwhereas\\nthe\\nsubsequent\\n8\\nchapters\\nemphasize\\npractical\\napplications,\\nalthough\\nthe\\n“decision\\nboundary”\\nseparat-\\ning\\nthese\\ntwo\\ncategories\\nis\\nrather\\n“fuzzy”.\\n\\nKecman\\nfirst\\npresents\\nan\\nintroduction\\non\\nthe\\nSVM,\\nexplaining\\nthe\\nbasic\\ntheory\\nand\\nimplementation\\naspects.\\nIn\\nthe\\nchapter\\ncontributed\\nby\\nMa\\nand\\nCherkassky,\\na\\nnovel\\napproach\\nto\\nnonlinear\\nclassification\\nusing\\na\\ncollection\\nof\\nseveral\\nsimple\\n(linear)\\nclassifiers\\nis\\nproposed\\nbased\\non\\na\\nnew\\nformulation\\nof\\nthe\\nlearning\\nproblem\\ncalled\\nmultiple\\nmodel\\nestimation.\\nPelckmans,\\nGoethals,\\nDe\\nBrabanter,\\nSuykens,\\nand\\nDe\\nMoor\\ndescribe\\ncomponentwise\\nLeast\\nSquares\\nSupport\\nVector\\nMachines\\n(LS-SVMs)\\nfor\\nthe\\nestimation\\nof\\nadditive\\nmodels\\nconsisting\\nof\\na\\nsum\\nof\\nnonlinear\\ncomponents.\\n'</li>\n",
       "\t<li>'VI\\nPreface\\n\\nMotivated\\nby\\nthe\\nstatistical\\nquery\\nmodel,\\nMitra,\\nMurthy\\nand\\nPal\\nstudy\\nan\\nactive\\nlearning\\nstrategy\\nto\\nsolve\\nthe\\nlarge\\nquadratic\\nprogramming\\nproblem\\nof\\nSVM\\ndesign\\nin\\ndata\\nmining\\napplications.\\nKaizhu\\nHuang,\\nHaiqin\\nYang,\\nKing,\\nand\\nLyu\\npropose\\na\\nunifying\\ntheory\\nof\\nthe\\nMaxi-Min\\nMargin\\nMachine\\n(M4)\\nthat\\nsubsumes\\nthe\\nSVM,\\nthe\\nminimax\\nprobability\\nmachine,\\nand\\nthe\\nlinear\\ndiscriminant\\nanalysis.\\nVogt\\nand\\nKecman\\npresent\\nan\\nactive-set\\nalgorithm\\nfor\\nquadratic\\nprogramming\\nproblems\\nin\\nSVMs,\\nas\\nan\\nalternative\\nto\\nworking-set\\n(decomposition)\\ntechniques,\\nespecially\\nwhen\\nthe\\ndata\\nset\\nis\\nnot\\ntoo\\nlarge,\\nthe\\nproblem\\nis\\nill-conditioned,\\nor\\nwhen\\nhigh\\nprecision\\nis\\nneeded.\\n\\nBeing\\naware\\nof\\nthe\\nabundance\\nof\\nmethods\\nfor\\nSVM\\nmodel\\nselection,\\nAnguita,\\nBoni,\\nRidella,\\nRivieccio,\\nand\\nSterpi\\ncarefully\\nanalyze\\nthe\\nmost\\nwell-\\nknown\\nmethods\\nand\\ntest\\nsome\\nof\\nthem\\non\\nstandard\\nbenchmarks\\nto\\nevaluate\\ntheir\\neffectiveness.\\nIn\\nan\\nattempt\\nto\\nminimize\\nbias,\\nPeng,\\nHeisterkamp,\\nand\\nDai\\npropose\\nlocally\\nadaptive\\nnearest\\nneighbor\\nclassification\\nmethods\\nby\\nusing\\nlocally\\nlinear\\nSVMs\\nand\\nquasiconformal\\ntransformed\\nkernels.\\nWilliams,\\nWu,\\nand\\nFeng\\ndiscuss\\ntwo\\ngeometric\\nmethods\\nto\\nimprove\\nSVM\\nperformance,\\ni.e.,\\n(1)\\nadapting\\nkernels\\nby\\nmagnifying\\nthe\\nRiemannian\\nmetric\\nin\\nthe\\nneighbor-\\nhood\\nof\\nthe\\nboundary,\\nthereby\\nincreasing\\nclass\\nseparation,\\nand\\n(2)\\noptimally\\nlocating\\nthe\\nseparating\\nboundary,\\ngiven\\nthat\\nthe\\ndistributions\\nof\\ndata\\non\\neither\\nside\\nmay\\nhave\\ndifferent\\nscales.\\n\\nSong,\\nHu,\\nand\\nXulei\\nYang\\nderive\\na\\nKuhn-Tucker\\ncondition\\nand\\na\\ndecom-\\nposition\\nalgorithm\\nfor\\nrobust\\nSVMs\\nto\\ndeal\\nwith\\noverfitting\\nin\\nthe\\npresence\\nof\\noutliers.\\nLin\\nand\\nSheng-de\\nWang\\ndesign\\na\\nfuzzy\\nSVM\\nwith\\nautomatic\\ndeter-\\nmination\\nof\\nthe\\nmembership\\nfunctions.\\nKecman,\\nTe-Ming\\nHuang,\\nand\\nVogt\\npresent\\nthe\\nlatest\\ndevelopments\\nand\\nresults\\nof\\nthe\\nIterative\\nSingle\\nData\\nAlgo-\\nrithm\\nfor\\nsolving\\nlarge-scale\\nproblems.\\n\\nExploiting\\nregularization\\nand\\nsubspace\\ndecomposition\\ntechniques,\\nLu,\\nPlataniotis,\\nand\\nVenetsanopoulos\\nintroduce\\na\\nnew\\nkernel\\ndiscriminant\\nlearn-\\ning\\nmethod\\nand\\napply\\nthe\\nmethod\\nto\\nface\\nrecognition.\\nKwang\\nIn\\nKim,\\nJung,\\nand\\nHang\\nJoon\\nKim\\nemploy\\nSVMs\\nand\\nneural\\nnetworks\\nfor\\nautomobile\\nli-\\ncense\\nplate\\nlocalization,\\nby\\nclassifying\\neach\\npixel\\nin\\nthe\\nimage\\ninto\\nthe\\nobject\\nof\\ninterest\\nor\\nthe\\nbackground\\nbased\\non\\nlocalized\\ncolor\\ntexture\\npatterns.\\nMat-\\ntera\\ndiscusses\\nSVM\\napplications\\nin\\nsignal\\nprocessing,\\nespecially\\nthe\\nproblem\\nof\\ndigital\\nchannel\\nequalization.\\nChu,\\nJin,\\nand\\nLipo\\nWang\\nuse\\nSVMs\\nto\\nsolve\\ntwo\\nimportant\\nproblems\\nin\\nbioinformatics,\\ni.e.,\\ncancer\\ndiagnosis\\nbased\\non\\nmi-\\ncroarray\\ngene\\nexpression\\ndata\\nand\\nprotein\\nsecondary\\nstructure\\nprediction.\\n\\nEmulating\\nthe\\nnatural\\nnose,\\nBrezmes,\\nLlobet,\\nAl-Khalifa,\\nMaldonado,\\nand\\nGardner\\ndescribe\\nhow\\nSVMs\\nare\\nbeing\\nevaluated\\nin\\nthe\\ngas\\nsensor\\ncommu-\\nnity\\nto\\ndiscriminate\\ndifferent\\nblends\\nof\\ncoffee,\\ndifferent\\ntypes\\nof\\nvapors\\nand\\nnerve\\nagents.\\nZhan\\npresents\\nan\\napplication\\nof\\nthe\\nSVM\\nin\\ninverse\\nproblems\\nin\\nocean\\ncolor\\nremote\\nsensing.\\nLiang\\nuses\\nSVMs\\nfor\\nnon-invasive\\ndiagnosis\\nof\\ndelayed\\ngastric\\nemptying\\nfrom\\nthe\\ncutaneous\\nelectrogastrograms\\n(EGGs).\\nRojo-Alvarez,\\nGarcia-Alberola,\\nArtés-Rodriguez,\\nand\\nArenal-Maiz\\napply\\nSVMs,\\ntogether\\nwith\\nbootstrap\\nresampling\\nand\\nprincipal\\ncomponent\\nanalysis,\\nto\\ntachycardia\\ndiscrimination\\nin\\nimplantable\\ncardioverter\\ndefibrillators.\\n'</li>\n",
       "\t<li>'Preface\\nVil\\nI\\nwould\\nlike\\nto\\nexpress\\nmy\\nsincere\\nappreciation\\nto\\nall\\nauthors\\nand\\nreviewers\\nwho\\nhave\\nspent\\ntheir\\nprecious\\ntime\\nand\\nefforts\\nin\\nmaking\\nthis\\nbook\\na\\nreality.\\nI\\nwish\\nto\\nespecially\\nthank\\nProfessor\\nVojislav\\nKecman,\\nwho\\ngraciously\\ntook\\non\\nthe\\nenormous\\ntask\\nof\\nwriting\\na\\ncomprehensive\\nintroductory\\nchapter,\\nin\\naddition\\nto\\nhis\\nother\\ngreat\\ncontributions\\nto\\nthis\\nbook.\\nMy\\ngratitude\\nalso\\ngoes\\nto\\nProfessor\\nJanusz\\nKacprzyk\\nand\\nDr.\\nThomas\\nDitzinger\\nfor\\ntheir\\nkindest\\nsupport\\nand\\nhelp\\nwith\\nthis\\nbook.\\nSingapore\\nLipo\\nWang\\nJanuary\\n2005\\n'</li>\n",
       "\t<li>''</li>\n",
       "\t<li>'Contents\\n\\nSupport\\nVector\\nMachines\\n—\\nAn\\nIntroduction\\n\\nV.\\nK€CMGN.\\n6.\\neee\\neee\\neee\\neee\\neeeeeee\\nMultiple\\nModel\\nEstimation\\n\\nfor\\nNonlinear\\nClassification\\n\\nY.\\nMa\\nand\\nV.\\nCherkassky\\n..\\n0.0.00.\\nAY\\nComponentwise\\nLeast\\nSquares\\nSupport\\nVector\\nMachines\\n\\nKk.\\nPelckmans,\\nI.\\nGoethals,\\nJ.\\nDe\\nBrabanter,\\nJ.A.K.\\nSuykens,\\nand\\nB.\\n\\nDe\\nMOor\\n..\\nccc\\nnee\\neee\\neee\\neee\\nTT\\nActive\\nSupport\\nVector\\nLearning\\nwith\\nStatistical\\nQueries\\n\\nP.\\nMitra,\\nC.A.\\nMurthy,\\nand\\nSK.\\nPal...\\neee\\nee\\nID\\nLocal\\nLearning\\nvs.\\nGlobal\\nLearning:\\nAn\\nIntroduction\\n\\nto\\nMaxi-Min\\nMargin\\nMachine\\n\\nKk.\\nHuang,\\nH.\\nYang,\\nI.\\nKing,\\nand\\nM.R.\\nLyu\\n.....\\neee\\neee\\nee\\nee\\nL18\\nActive-Set\\nMethods\\nfor\\nSupport\\nVector\\nMachines\\n\\nM.\\nVogt\\nand\\nV.\\nKecman\\n...\\n6...\\ncece\\nee\\neee\\nee\\nA\\n138\\nTheoretical\\nand\\nPractical\\nModel\\nSelection\\nMethods\\n\\nfor\\nSupport\\nVector\\nClassifiers\\n\\nD.\\nAnguita,\\nA.\\nBoni,\\nS.\\nRidella,\\nFP.\\nRivieccio,\\nand\\nD.\\nSterpi...........159\\nAdaptive\\nDiscriminant\\n\\nand\\nQuasiconformal\\nKernel\\nNearest\\nNeighbor\\nClassification\\n\\nJ.\\nPeng,\\nD.R.\\nHeisterkamp,\\nand\\nH.K.\\nDat\\n..\\n1...\\nee\\nee\\nLB\\nImproving\\nthe\\nPerformance\\nof\\nthe\\nSupport\\nVector\\nMachine:\\n\\nTwo\\nGeometrical\\nScaling\\nMethods\\n\\nP.\\nWilliams,\\nS.\\nWu,\\nand\\nJ.\\nFeng\\n0.0...\\nccc\\ncee\\neee\\nee\\n205\\n'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'Support\\textbackslash{}nVector\\textbackslash{}nMachines:\\textbackslash{}nTheory\\textbackslash{}nand\\textbackslash{}nApplications\\textbackslash{}nLipo\\textbackslash{}nWang\\textbackslash{}n(ed.)\\textbackslash{}n\\textbackslash{}nSpringer,\\textbackslash{}nBerlin\\textbackslash{}n2005\\textbackslash{}n'\n",
       "\\item 'Preface\\textbackslash{}n\\textbackslash{}nThe\\textbackslash{}nsupport\\textbackslash{}nvector\\textbackslash{}nmachine\\textbackslash{}n(SVM)\\textbackslash{}nis\\textbackslash{}na\\textbackslash{}nsupervised\\textbackslash{}nlearning\\textbackslash{}nmethod\\textbackslash{}nthat\\textbackslash{}ngenerates\\textbackslash{}ninput-output\\textbackslash{}nmapping\\textbackslash{}nfunctions\\textbackslash{}nfrom\\textbackslash{}na\\textbackslash{}nset\\textbackslash{}nof\\textbackslash{}nlabeled\\textbackslash{}ntraining\\textbackslash{}ndata.\\textbackslash{}nThe\\textbackslash{}nmapping\\textbackslash{}nfunction\\textbackslash{}ncan\\textbackslash{}nbe\\textbackslash{}neither\\textbackslash{}na\\textbackslash{}nclassification\\textbackslash{}nfunction,\\textbackslash{}ni.e.,\\textbackslash{}nthe\\textbackslash{}ncate-\\textbackslash{}ngory\\textbackslash{}nof\\textbackslash{}nthe\\textbackslash{}ninput\\textbackslash{}ndata,\\textbackslash{}nor\\textbackslash{}na\\textbackslash{}nregression\\textbackslash{}nfunction.\\textbackslash{}nFor\\textbackslash{}nclassification,\\textbackslash{}nnonlinear\\textbackslash{}nkernel\\textbackslash{}nfunctions\\textbackslash{}nare\\textbackslash{}noften\\textbackslash{}nused\\textbackslash{}nto\\textbackslash{}ntransform\\textbackslash{}ninput\\textbackslash{}ndata\\textbackslash{}nto\\textbackslash{}na\\textbackslash{}nhigh-dimensional\\textbackslash{}nfeature\\textbackslash{}nspace\\textbackslash{}nin\\textbackslash{}nwhich\\textbackslash{}nthe\\textbackslash{}ninput\\textbackslash{}ndata\\textbackslash{}nbecome\\textbackslash{}nmore\\textbackslash{}nseparable\\textbackslash{}ncompared\\textbackslash{}nto\\textbackslash{}nthe\\textbackslash{}noriginal\\textbackslash{}ninput\\textbackslash{}nspace.\\textbackslash{}nMaximum-margin\\textbackslash{}nhyperplanes\\textbackslash{}nare\\textbackslash{}nthen\\textbackslash{}ncreated.\\textbackslash{}n‘The\\textbackslash{}nmodel\\textbackslash{}nthus\\textbackslash{}nproduced\\textbackslash{}ndepends\\textbackslash{}non\\textbackslash{}nonly\\textbackslash{}na\\textbackslash{}nsubset\\textbackslash{}nof\\textbackslash{}nthe\\textbackslash{}ntraining\\textbackslash{}ndata\\textbackslash{}nnear\\textbackslash{}nthe\\textbackslash{}nclass\\textbackslash{}nboundaries.\\textbackslash{}nSimilarly,\\textbackslash{}nthe\\textbackslash{}nmodel\\textbackslash{}nproduced\\textbackslash{}nby\\textbackslash{}nSupport\\textbackslash{}nVector\\textbackslash{}nRegres-\\textbackslash{}nsion\\textbackslash{}nignores\\textbackslash{}nany\\textbackslash{}ntraining\\textbackslash{}ndata\\textbackslash{}nthat\\textbackslash{}nis\\textbackslash{}nsufficiently\\textbackslash{}nclose\\textbackslash{}nto\\textbackslash{}nthe\\textbackslash{}nmodel\\textbackslash{}nprediction.\\textbackslash{}nSVMs\\textbackslash{}nare\\textbackslash{}nalso\\textbackslash{}nsaid\\textbackslash{}nto\\textbackslash{}nbelong\\textbackslash{}nto\\textbackslash{}n“kernel\\textbackslash{}nmethods”.\\textbackslash{}n\\textbackslash{}nIn\\textbackslash{}naddition\\textbackslash{}nto\\textbackslash{}nits\\textbackslash{}nsolid\\textbackslash{}nmathematical\\textbackslash{}nfoundation\\textbackslash{}nin\\textbackslash{}nstatistical\\textbackslash{}nlearning\\textbackslash{}ntheory,\\textbackslash{}nSVMs\\textbackslash{}nhave\\textbackslash{}ndemonstrated\\textbackslash{}nhighly\\textbackslash{}ncompetitive\\textbackslash{}nperformance\\textbackslash{}nin\\textbackslash{}nnumerous\\textbackslash{}nreal-world\\textbackslash{}napplications,\\textbackslash{}nsuch\\textbackslash{}nas\\textbackslash{}nbioinformatics,\\textbackslash{}ntext\\textbackslash{}nmining,\\textbackslash{}nface\\textbackslash{}nrecognition,\\textbackslash{}nand\\textbackslash{}nimage\\textbackslash{}nprocessing,\\textbackslash{}nwhich\\textbackslash{}nhas\\textbackslash{}nestablished\\textbackslash{}nSVMs\\textbackslash{}nas\\textbackslash{}none\\textbackslash{}nof\\textbackslash{}nthe\\textbackslash{}nstate-of-\\textbackslash{}nthe-art\\textbackslash{}ntools\\textbackslash{}nfor\\textbackslash{}nmachine\\textbackslash{}nlearning\\textbackslash{}nand\\textbackslash{}ndata\\textbackslash{}nmining,\\textbackslash{}nalong\\textbackslash{}nwith\\textbackslash{}nother\\textbackslash{}nsoft\\textbackslash{}ncomputing\\textbackslash{}ntechniques,\\textbackslash{}ne.g.,\\textbackslash{}nneural\\textbackslash{}nnetworks\\textbackslash{}nand\\textbackslash{}nfuzzy\\textbackslash{}nsystems.\\textbackslash{}n\\textbackslash{}nThis\\textbackslash{}nvolume\\textbackslash{}nis\\textbackslash{}ncomposed\\textbackslash{}nof\\textbackslash{}n20\\textbackslash{}nchapters\\textbackslash{}nselected\\textbackslash{}nfrom\\textbackslash{}nthe\\textbackslash{}nrecent\\textbackslash{}nmyriad\\textbackslash{}nof\\textbackslash{}nnovel\\textbackslash{}nSVM\\textbackslash{}napplications,\\textbackslash{}npowerful\\textbackslash{}nSVM\\textbackslash{}nalgorithms,\\textbackslash{}nas\\textbackslash{}nwell\\textbackslash{}nas\\textbackslash{}nenlighten-\\textbackslash{}ning\\textbackslash{}ntheoretical\\textbackslash{}nanalysis.\\textbackslash{}nWritten\\textbackslash{}nby\\textbackslash{}nexperts\\textbackslash{}nin\\textbackslash{}ntheir\\textbackslash{}nrespective\\textbackslash{}nfields,\\textbackslash{}nthe\\textbackslash{}nfirst\\textbackslash{}n12\\textbackslash{}nchapters\\textbackslash{}nconcentrate\\textbackslash{}non\\textbackslash{}nSVM\\textbackslash{}ntheory,\\textbackslash{}nwhereas\\textbackslash{}nthe\\textbackslash{}nsubsequent\\textbackslash{}n8\\textbackslash{}nchapters\\textbackslash{}nemphasize\\textbackslash{}npractical\\textbackslash{}napplications,\\textbackslash{}nalthough\\textbackslash{}nthe\\textbackslash{}n“decision\\textbackslash{}nboundary”\\textbackslash{}nseparat-\\textbackslash{}ning\\textbackslash{}nthese\\textbackslash{}ntwo\\textbackslash{}ncategories\\textbackslash{}nis\\textbackslash{}nrather\\textbackslash{}n“fuzzy”.\\textbackslash{}n\\textbackslash{}nKecman\\textbackslash{}nfirst\\textbackslash{}npresents\\textbackslash{}nan\\textbackslash{}nintroduction\\textbackslash{}non\\textbackslash{}nthe\\textbackslash{}nSVM,\\textbackslash{}nexplaining\\textbackslash{}nthe\\textbackslash{}nbasic\\textbackslash{}ntheory\\textbackslash{}nand\\textbackslash{}nimplementation\\textbackslash{}naspects.\\textbackslash{}nIn\\textbackslash{}nthe\\textbackslash{}nchapter\\textbackslash{}ncontributed\\textbackslash{}nby\\textbackslash{}nMa\\textbackslash{}nand\\textbackslash{}nCherkassky,\\textbackslash{}na\\textbackslash{}nnovel\\textbackslash{}napproach\\textbackslash{}nto\\textbackslash{}nnonlinear\\textbackslash{}nclassification\\textbackslash{}nusing\\textbackslash{}na\\textbackslash{}ncollection\\textbackslash{}nof\\textbackslash{}nseveral\\textbackslash{}nsimple\\textbackslash{}n(linear)\\textbackslash{}nclassifiers\\textbackslash{}nis\\textbackslash{}nproposed\\textbackslash{}nbased\\textbackslash{}non\\textbackslash{}na\\textbackslash{}nnew\\textbackslash{}nformulation\\textbackslash{}nof\\textbackslash{}nthe\\textbackslash{}nlearning\\textbackslash{}nproblem\\textbackslash{}ncalled\\textbackslash{}nmultiple\\textbackslash{}nmodel\\textbackslash{}nestimation.\\textbackslash{}nPelckmans,\\textbackslash{}nGoethals,\\textbackslash{}nDe\\textbackslash{}nBrabanter,\\textbackslash{}nSuykens,\\textbackslash{}nand\\textbackslash{}nDe\\textbackslash{}nMoor\\textbackslash{}ndescribe\\textbackslash{}ncomponentwise\\textbackslash{}nLeast\\textbackslash{}nSquares\\textbackslash{}nSupport\\textbackslash{}nVector\\textbackslash{}nMachines\\textbackslash{}n(LS-SVMs)\\textbackslash{}nfor\\textbackslash{}nthe\\textbackslash{}nestimation\\textbackslash{}nof\\textbackslash{}nadditive\\textbackslash{}nmodels\\textbackslash{}nconsisting\\textbackslash{}nof\\textbackslash{}na\\textbackslash{}nsum\\textbackslash{}nof\\textbackslash{}nnonlinear\\textbackslash{}ncomponents.\\textbackslash{}n'\n",
       "\\item 'VI\\textbackslash{}nPreface\\textbackslash{}n\\textbackslash{}nMotivated\\textbackslash{}nby\\textbackslash{}nthe\\textbackslash{}nstatistical\\textbackslash{}nquery\\textbackslash{}nmodel,\\textbackslash{}nMitra,\\textbackslash{}nMurthy\\textbackslash{}nand\\textbackslash{}nPal\\textbackslash{}nstudy\\textbackslash{}nan\\textbackslash{}nactive\\textbackslash{}nlearning\\textbackslash{}nstrategy\\textbackslash{}nto\\textbackslash{}nsolve\\textbackslash{}nthe\\textbackslash{}nlarge\\textbackslash{}nquadratic\\textbackslash{}nprogramming\\textbackslash{}nproblem\\textbackslash{}nof\\textbackslash{}nSVM\\textbackslash{}ndesign\\textbackslash{}nin\\textbackslash{}ndata\\textbackslash{}nmining\\textbackslash{}napplications.\\textbackslash{}nKaizhu\\textbackslash{}nHuang,\\textbackslash{}nHaiqin\\textbackslash{}nYang,\\textbackslash{}nKing,\\textbackslash{}nand\\textbackslash{}nLyu\\textbackslash{}npropose\\textbackslash{}na\\textbackslash{}nunifying\\textbackslash{}ntheory\\textbackslash{}nof\\textbackslash{}nthe\\textbackslash{}nMaxi-Min\\textbackslash{}nMargin\\textbackslash{}nMachine\\textbackslash{}n(M4)\\textbackslash{}nthat\\textbackslash{}nsubsumes\\textbackslash{}nthe\\textbackslash{}nSVM,\\textbackslash{}nthe\\textbackslash{}nminimax\\textbackslash{}nprobability\\textbackslash{}nmachine,\\textbackslash{}nand\\textbackslash{}nthe\\textbackslash{}nlinear\\textbackslash{}ndiscriminant\\textbackslash{}nanalysis.\\textbackslash{}nVogt\\textbackslash{}nand\\textbackslash{}nKecman\\textbackslash{}npresent\\textbackslash{}nan\\textbackslash{}nactive-set\\textbackslash{}nalgorithm\\textbackslash{}nfor\\textbackslash{}nquadratic\\textbackslash{}nprogramming\\textbackslash{}nproblems\\textbackslash{}nin\\textbackslash{}nSVMs,\\textbackslash{}nas\\textbackslash{}nan\\textbackslash{}nalternative\\textbackslash{}nto\\textbackslash{}nworking-set\\textbackslash{}n(decomposition)\\textbackslash{}ntechniques,\\textbackslash{}nespecially\\textbackslash{}nwhen\\textbackslash{}nthe\\textbackslash{}ndata\\textbackslash{}nset\\textbackslash{}nis\\textbackslash{}nnot\\textbackslash{}ntoo\\textbackslash{}nlarge,\\textbackslash{}nthe\\textbackslash{}nproblem\\textbackslash{}nis\\textbackslash{}nill-conditioned,\\textbackslash{}nor\\textbackslash{}nwhen\\textbackslash{}nhigh\\textbackslash{}nprecision\\textbackslash{}nis\\textbackslash{}nneeded.\\textbackslash{}n\\textbackslash{}nBeing\\textbackslash{}naware\\textbackslash{}nof\\textbackslash{}nthe\\textbackslash{}nabundance\\textbackslash{}nof\\textbackslash{}nmethods\\textbackslash{}nfor\\textbackslash{}nSVM\\textbackslash{}nmodel\\textbackslash{}nselection,\\textbackslash{}nAnguita,\\textbackslash{}nBoni,\\textbackslash{}nRidella,\\textbackslash{}nRivieccio,\\textbackslash{}nand\\textbackslash{}nSterpi\\textbackslash{}ncarefully\\textbackslash{}nanalyze\\textbackslash{}nthe\\textbackslash{}nmost\\textbackslash{}nwell-\\textbackslash{}nknown\\textbackslash{}nmethods\\textbackslash{}nand\\textbackslash{}ntest\\textbackslash{}nsome\\textbackslash{}nof\\textbackslash{}nthem\\textbackslash{}non\\textbackslash{}nstandard\\textbackslash{}nbenchmarks\\textbackslash{}nto\\textbackslash{}nevaluate\\textbackslash{}ntheir\\textbackslash{}neffectiveness.\\textbackslash{}nIn\\textbackslash{}nan\\textbackslash{}nattempt\\textbackslash{}nto\\textbackslash{}nminimize\\textbackslash{}nbias,\\textbackslash{}nPeng,\\textbackslash{}nHeisterkamp,\\textbackslash{}nand\\textbackslash{}nDai\\textbackslash{}npropose\\textbackslash{}nlocally\\textbackslash{}nadaptive\\textbackslash{}nnearest\\textbackslash{}nneighbor\\textbackslash{}nclassification\\textbackslash{}nmethods\\textbackslash{}nby\\textbackslash{}nusing\\textbackslash{}nlocally\\textbackslash{}nlinear\\textbackslash{}nSVMs\\textbackslash{}nand\\textbackslash{}nquasiconformal\\textbackslash{}ntransformed\\textbackslash{}nkernels.\\textbackslash{}nWilliams,\\textbackslash{}nWu,\\textbackslash{}nand\\textbackslash{}nFeng\\textbackslash{}ndiscuss\\textbackslash{}ntwo\\textbackslash{}ngeometric\\textbackslash{}nmethods\\textbackslash{}nto\\textbackslash{}nimprove\\textbackslash{}nSVM\\textbackslash{}nperformance,\\textbackslash{}ni.e.,\\textbackslash{}n(1)\\textbackslash{}nadapting\\textbackslash{}nkernels\\textbackslash{}nby\\textbackslash{}nmagnifying\\textbackslash{}nthe\\textbackslash{}nRiemannian\\textbackslash{}nmetric\\textbackslash{}nin\\textbackslash{}nthe\\textbackslash{}nneighbor-\\textbackslash{}nhood\\textbackslash{}nof\\textbackslash{}nthe\\textbackslash{}nboundary,\\textbackslash{}nthereby\\textbackslash{}nincreasing\\textbackslash{}nclass\\textbackslash{}nseparation,\\textbackslash{}nand\\textbackslash{}n(2)\\textbackslash{}noptimally\\textbackslash{}nlocating\\textbackslash{}nthe\\textbackslash{}nseparating\\textbackslash{}nboundary,\\textbackslash{}ngiven\\textbackslash{}nthat\\textbackslash{}nthe\\textbackslash{}ndistributions\\textbackslash{}nof\\textbackslash{}ndata\\textbackslash{}non\\textbackslash{}neither\\textbackslash{}nside\\textbackslash{}nmay\\textbackslash{}nhave\\textbackslash{}ndifferent\\textbackslash{}nscales.\\textbackslash{}n\\textbackslash{}nSong,\\textbackslash{}nHu,\\textbackslash{}nand\\textbackslash{}nXulei\\textbackslash{}nYang\\textbackslash{}nderive\\textbackslash{}na\\textbackslash{}nKuhn-Tucker\\textbackslash{}ncondition\\textbackslash{}nand\\textbackslash{}na\\textbackslash{}ndecom-\\textbackslash{}nposition\\textbackslash{}nalgorithm\\textbackslash{}nfor\\textbackslash{}nrobust\\textbackslash{}nSVMs\\textbackslash{}nto\\textbackslash{}ndeal\\textbackslash{}nwith\\textbackslash{}noverfitting\\textbackslash{}nin\\textbackslash{}nthe\\textbackslash{}npresence\\textbackslash{}nof\\textbackslash{}noutliers.\\textbackslash{}nLin\\textbackslash{}nand\\textbackslash{}nSheng-de\\textbackslash{}nWang\\textbackslash{}ndesign\\textbackslash{}na\\textbackslash{}nfuzzy\\textbackslash{}nSVM\\textbackslash{}nwith\\textbackslash{}nautomatic\\textbackslash{}ndeter-\\textbackslash{}nmination\\textbackslash{}nof\\textbackslash{}nthe\\textbackslash{}nmembership\\textbackslash{}nfunctions.\\textbackslash{}nKecman,\\textbackslash{}nTe-Ming\\textbackslash{}nHuang,\\textbackslash{}nand\\textbackslash{}nVogt\\textbackslash{}npresent\\textbackslash{}nthe\\textbackslash{}nlatest\\textbackslash{}ndevelopments\\textbackslash{}nand\\textbackslash{}nresults\\textbackslash{}nof\\textbackslash{}nthe\\textbackslash{}nIterative\\textbackslash{}nSingle\\textbackslash{}nData\\textbackslash{}nAlgo-\\textbackslash{}nrithm\\textbackslash{}nfor\\textbackslash{}nsolving\\textbackslash{}nlarge-scale\\textbackslash{}nproblems.\\textbackslash{}n\\textbackslash{}nExploiting\\textbackslash{}nregularization\\textbackslash{}nand\\textbackslash{}nsubspace\\textbackslash{}ndecomposition\\textbackslash{}ntechniques,\\textbackslash{}nLu,\\textbackslash{}nPlataniotis,\\textbackslash{}nand\\textbackslash{}nVenetsanopoulos\\textbackslash{}nintroduce\\textbackslash{}na\\textbackslash{}nnew\\textbackslash{}nkernel\\textbackslash{}ndiscriminant\\textbackslash{}nlearn-\\textbackslash{}ning\\textbackslash{}nmethod\\textbackslash{}nand\\textbackslash{}napply\\textbackslash{}nthe\\textbackslash{}nmethod\\textbackslash{}nto\\textbackslash{}nface\\textbackslash{}nrecognition.\\textbackslash{}nKwang\\textbackslash{}nIn\\textbackslash{}nKim,\\textbackslash{}nJung,\\textbackslash{}nand\\textbackslash{}nHang\\textbackslash{}nJoon\\textbackslash{}nKim\\textbackslash{}nemploy\\textbackslash{}nSVMs\\textbackslash{}nand\\textbackslash{}nneural\\textbackslash{}nnetworks\\textbackslash{}nfor\\textbackslash{}nautomobile\\textbackslash{}nli-\\textbackslash{}ncense\\textbackslash{}nplate\\textbackslash{}nlocalization,\\textbackslash{}nby\\textbackslash{}nclassifying\\textbackslash{}neach\\textbackslash{}npixel\\textbackslash{}nin\\textbackslash{}nthe\\textbackslash{}nimage\\textbackslash{}ninto\\textbackslash{}nthe\\textbackslash{}nobject\\textbackslash{}nof\\textbackslash{}ninterest\\textbackslash{}nor\\textbackslash{}nthe\\textbackslash{}nbackground\\textbackslash{}nbased\\textbackslash{}non\\textbackslash{}nlocalized\\textbackslash{}ncolor\\textbackslash{}ntexture\\textbackslash{}npatterns.\\textbackslash{}nMat-\\textbackslash{}ntera\\textbackslash{}ndiscusses\\textbackslash{}nSVM\\textbackslash{}napplications\\textbackslash{}nin\\textbackslash{}nsignal\\textbackslash{}nprocessing,\\textbackslash{}nespecially\\textbackslash{}nthe\\textbackslash{}nproblem\\textbackslash{}nof\\textbackslash{}ndigital\\textbackslash{}nchannel\\textbackslash{}nequalization.\\textbackslash{}nChu,\\textbackslash{}nJin,\\textbackslash{}nand\\textbackslash{}nLipo\\textbackslash{}nWang\\textbackslash{}nuse\\textbackslash{}nSVMs\\textbackslash{}nto\\textbackslash{}nsolve\\textbackslash{}ntwo\\textbackslash{}nimportant\\textbackslash{}nproblems\\textbackslash{}nin\\textbackslash{}nbioinformatics,\\textbackslash{}ni.e.,\\textbackslash{}ncancer\\textbackslash{}ndiagnosis\\textbackslash{}nbased\\textbackslash{}non\\textbackslash{}nmi-\\textbackslash{}ncroarray\\textbackslash{}ngene\\textbackslash{}nexpression\\textbackslash{}ndata\\textbackslash{}nand\\textbackslash{}nprotein\\textbackslash{}nsecondary\\textbackslash{}nstructure\\textbackslash{}nprediction.\\textbackslash{}n\\textbackslash{}nEmulating\\textbackslash{}nthe\\textbackslash{}nnatural\\textbackslash{}nnose,\\textbackslash{}nBrezmes,\\textbackslash{}nLlobet,\\textbackslash{}nAl-Khalifa,\\textbackslash{}nMaldonado,\\textbackslash{}nand\\textbackslash{}nGardner\\textbackslash{}ndescribe\\textbackslash{}nhow\\textbackslash{}nSVMs\\textbackslash{}nare\\textbackslash{}nbeing\\textbackslash{}nevaluated\\textbackslash{}nin\\textbackslash{}nthe\\textbackslash{}ngas\\textbackslash{}nsensor\\textbackslash{}ncommu-\\textbackslash{}nnity\\textbackslash{}nto\\textbackslash{}ndiscriminate\\textbackslash{}ndifferent\\textbackslash{}nblends\\textbackslash{}nof\\textbackslash{}ncoffee,\\textbackslash{}ndifferent\\textbackslash{}ntypes\\textbackslash{}nof\\textbackslash{}nvapors\\textbackslash{}nand\\textbackslash{}nnerve\\textbackslash{}nagents.\\textbackslash{}nZhan\\textbackslash{}npresents\\textbackslash{}nan\\textbackslash{}napplication\\textbackslash{}nof\\textbackslash{}nthe\\textbackslash{}nSVM\\textbackslash{}nin\\textbackslash{}ninverse\\textbackslash{}nproblems\\textbackslash{}nin\\textbackslash{}nocean\\textbackslash{}ncolor\\textbackslash{}nremote\\textbackslash{}nsensing.\\textbackslash{}nLiang\\textbackslash{}nuses\\textbackslash{}nSVMs\\textbackslash{}nfor\\textbackslash{}nnon-invasive\\textbackslash{}ndiagnosis\\textbackslash{}nof\\textbackslash{}ndelayed\\textbackslash{}ngastric\\textbackslash{}nemptying\\textbackslash{}nfrom\\textbackslash{}nthe\\textbackslash{}ncutaneous\\textbackslash{}nelectrogastrograms\\textbackslash{}n(EGGs).\\textbackslash{}nRojo-Alvarez,\\textbackslash{}nGarcia-Alberola,\\textbackslash{}nArtés-Rodriguez,\\textbackslash{}nand\\textbackslash{}nArenal-Maiz\\textbackslash{}napply\\textbackslash{}nSVMs,\\textbackslash{}ntogether\\textbackslash{}nwith\\textbackslash{}nbootstrap\\textbackslash{}nresampling\\textbackslash{}nand\\textbackslash{}nprincipal\\textbackslash{}ncomponent\\textbackslash{}nanalysis,\\textbackslash{}nto\\textbackslash{}ntachycardia\\textbackslash{}ndiscrimination\\textbackslash{}nin\\textbackslash{}nimplantable\\textbackslash{}ncardioverter\\textbackslash{}ndefibrillators.\\textbackslash{}n'\n",
       "\\item 'Preface\\textbackslash{}nVil\\textbackslash{}nI\\textbackslash{}nwould\\textbackslash{}nlike\\textbackslash{}nto\\textbackslash{}nexpress\\textbackslash{}nmy\\textbackslash{}nsincere\\textbackslash{}nappreciation\\textbackslash{}nto\\textbackslash{}nall\\textbackslash{}nauthors\\textbackslash{}nand\\textbackslash{}nreviewers\\textbackslash{}nwho\\textbackslash{}nhave\\textbackslash{}nspent\\textbackslash{}ntheir\\textbackslash{}nprecious\\textbackslash{}ntime\\textbackslash{}nand\\textbackslash{}nefforts\\textbackslash{}nin\\textbackslash{}nmaking\\textbackslash{}nthis\\textbackslash{}nbook\\textbackslash{}na\\textbackslash{}nreality.\\textbackslash{}nI\\textbackslash{}nwish\\textbackslash{}nto\\textbackslash{}nespecially\\textbackslash{}nthank\\textbackslash{}nProfessor\\textbackslash{}nVojislav\\textbackslash{}nKecman,\\textbackslash{}nwho\\textbackslash{}ngraciously\\textbackslash{}ntook\\textbackslash{}non\\textbackslash{}nthe\\textbackslash{}nenormous\\textbackslash{}ntask\\textbackslash{}nof\\textbackslash{}nwriting\\textbackslash{}na\\textbackslash{}ncomprehensive\\textbackslash{}nintroductory\\textbackslash{}nchapter,\\textbackslash{}nin\\textbackslash{}naddition\\textbackslash{}nto\\textbackslash{}nhis\\textbackslash{}nother\\textbackslash{}ngreat\\textbackslash{}ncontributions\\textbackslash{}nto\\textbackslash{}nthis\\textbackslash{}nbook.\\textbackslash{}nMy\\textbackslash{}ngratitude\\textbackslash{}nalso\\textbackslash{}ngoes\\textbackslash{}nto\\textbackslash{}nProfessor\\textbackslash{}nJanusz\\textbackslash{}nKacprzyk\\textbackslash{}nand\\textbackslash{}nDr.\\textbackslash{}nThomas\\textbackslash{}nDitzinger\\textbackslash{}nfor\\textbackslash{}ntheir\\textbackslash{}nkindest\\textbackslash{}nsupport\\textbackslash{}nand\\textbackslash{}nhelp\\textbackslash{}nwith\\textbackslash{}nthis\\textbackslash{}nbook.\\textbackslash{}nSingapore\\textbackslash{}nLipo\\textbackslash{}nWang\\textbackslash{}nJanuary\\textbackslash{}n2005\\textbackslash{}n'\n",
       "\\item ''\n",
       "\\item 'Contents\\textbackslash{}n\\textbackslash{}nSupport\\textbackslash{}nVector\\textbackslash{}nMachines\\textbackslash{}n—\\textbackslash{}nAn\\textbackslash{}nIntroduction\\textbackslash{}n\\textbackslash{}nV.\\textbackslash{}nK€CMGN.\\textbackslash{}n6.\\textbackslash{}neee\\textbackslash{}neee\\textbackslash{}neee\\textbackslash{}neee\\textbackslash{}neeeeeee\\textbackslash{}nMultiple\\textbackslash{}nModel\\textbackslash{}nEstimation\\textbackslash{}n\\textbackslash{}nfor\\textbackslash{}nNonlinear\\textbackslash{}nClassification\\textbackslash{}n\\textbackslash{}nY.\\textbackslash{}nMa\\textbackslash{}nand\\textbackslash{}nV.\\textbackslash{}nCherkassky\\textbackslash{}n..\\textbackslash{}n0.0.00.\\textbackslash{}nAY\\textbackslash{}nComponentwise\\textbackslash{}nLeast\\textbackslash{}nSquares\\textbackslash{}nSupport\\textbackslash{}nVector\\textbackslash{}nMachines\\textbackslash{}n\\textbackslash{}nKk.\\textbackslash{}nPelckmans,\\textbackslash{}nI.\\textbackslash{}nGoethals,\\textbackslash{}nJ.\\textbackslash{}nDe\\textbackslash{}nBrabanter,\\textbackslash{}nJ.A.K.\\textbackslash{}nSuykens,\\textbackslash{}nand\\textbackslash{}nB.\\textbackslash{}n\\textbackslash{}nDe\\textbackslash{}nMOor\\textbackslash{}n..\\textbackslash{}nccc\\textbackslash{}nnee\\textbackslash{}neee\\textbackslash{}neee\\textbackslash{}neee\\textbackslash{}nTT\\textbackslash{}nActive\\textbackslash{}nSupport\\textbackslash{}nVector\\textbackslash{}nLearning\\textbackslash{}nwith\\textbackslash{}nStatistical\\textbackslash{}nQueries\\textbackslash{}n\\textbackslash{}nP.\\textbackslash{}nMitra,\\textbackslash{}nC.A.\\textbackslash{}nMurthy,\\textbackslash{}nand\\textbackslash{}nSK.\\textbackslash{}nPal...\\textbackslash{}neee\\textbackslash{}nee\\textbackslash{}nID\\textbackslash{}nLocal\\textbackslash{}nLearning\\textbackslash{}nvs.\\textbackslash{}nGlobal\\textbackslash{}nLearning:\\textbackslash{}nAn\\textbackslash{}nIntroduction\\textbackslash{}n\\textbackslash{}nto\\textbackslash{}nMaxi-Min\\textbackslash{}nMargin\\textbackslash{}nMachine\\textbackslash{}n\\textbackslash{}nKk.\\textbackslash{}nHuang,\\textbackslash{}nH.\\textbackslash{}nYang,\\textbackslash{}nI.\\textbackslash{}nKing,\\textbackslash{}nand\\textbackslash{}nM.R.\\textbackslash{}nLyu\\textbackslash{}n.....\\textbackslash{}neee\\textbackslash{}neee\\textbackslash{}nee\\textbackslash{}nee\\textbackslash{}nL18\\textbackslash{}nActive-Set\\textbackslash{}nMethods\\textbackslash{}nfor\\textbackslash{}nSupport\\textbackslash{}nVector\\textbackslash{}nMachines\\textbackslash{}n\\textbackslash{}nM.\\textbackslash{}nVogt\\textbackslash{}nand\\textbackslash{}nV.\\textbackslash{}nKecman\\textbackslash{}n...\\textbackslash{}n6...\\textbackslash{}ncece\\textbackslash{}nee\\textbackslash{}neee\\textbackslash{}nee\\textbackslash{}nA\\textbackslash{}n138\\textbackslash{}nTheoretical\\textbackslash{}nand\\textbackslash{}nPractical\\textbackslash{}nModel\\textbackslash{}nSelection\\textbackslash{}nMethods\\textbackslash{}n\\textbackslash{}nfor\\textbackslash{}nSupport\\textbackslash{}nVector\\textbackslash{}nClassifiers\\textbackslash{}n\\textbackslash{}nD.\\textbackslash{}nAnguita,\\textbackslash{}nA.\\textbackslash{}nBoni,\\textbackslash{}nS.\\textbackslash{}nRidella,\\textbackslash{}nFP.\\textbackslash{}nRivieccio,\\textbackslash{}nand\\textbackslash{}nD.\\textbackslash{}nSterpi...........159\\textbackslash{}nAdaptive\\textbackslash{}nDiscriminant\\textbackslash{}n\\textbackslash{}nand\\textbackslash{}nQuasiconformal\\textbackslash{}nKernel\\textbackslash{}nNearest\\textbackslash{}nNeighbor\\textbackslash{}nClassification\\textbackslash{}n\\textbackslash{}nJ.\\textbackslash{}nPeng,\\textbackslash{}nD.R.\\textbackslash{}nHeisterkamp,\\textbackslash{}nand\\textbackslash{}nH.K.\\textbackslash{}nDat\\textbackslash{}n..\\textbackslash{}n1...\\textbackslash{}nee\\textbackslash{}nee\\textbackslash{}nLB\\textbackslash{}nImproving\\textbackslash{}nthe\\textbackslash{}nPerformance\\textbackslash{}nof\\textbackslash{}nthe\\textbackslash{}nSupport\\textbackslash{}nVector\\textbackslash{}nMachine:\\textbackslash{}n\\textbackslash{}nTwo\\textbackslash{}nGeometrical\\textbackslash{}nScaling\\textbackslash{}nMethods\\textbackslash{}n\\textbackslash{}nP.\\textbackslash{}nWilliams,\\textbackslash{}nS.\\textbackslash{}nWu,\\textbackslash{}nand\\textbackslash{}nJ.\\textbackslash{}nFeng\\textbackslash{}n0.0...\\textbackslash{}nccc\\textbackslash{}ncee\\textbackslash{}neee\\textbackslash{}nee\\textbackslash{}n205\\textbackslash{}n'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'Support\\nVector\\nMachines:\\nTheory\\nand\\nApplications\\nLipo\\nWang\\n(ed.)\\n\\nSpringer,\\nBerlin\\n2005\\n'\n",
       "2. 'Preface\\n\\nThe\\nsupport\\nvector\\nmachine\\n(SVM)\\nis\\na\\nsupervised\\nlearning\\nmethod\\nthat\\ngenerates\\ninput-output\\nmapping\\nfunctions\\nfrom\\na\\nset\\nof\\nlabeled\\ntraining\\ndata.\\nThe\\nmapping\\nfunction\\ncan\\nbe\\neither\\na\\nclassification\\nfunction,\\ni.e.,\\nthe\\ncate-\\ngory\\nof\\nthe\\ninput\\ndata,\\nor\\na\\nregression\\nfunction.\\nFor\\nclassification,\\nnonlinear\\nkernel\\nfunctions\\nare\\noften\\nused\\nto\\ntransform\\ninput\\ndata\\nto\\na\\nhigh-dimensional\\nfeature\\nspace\\nin\\nwhich\\nthe\\ninput\\ndata\\nbecome\\nmore\\nseparable\\ncompared\\nto\\nthe\\noriginal\\ninput\\nspace.\\nMaximum-margin\\nhyperplanes\\nare\\nthen\\ncreated.\\n‘The\\nmodel\\nthus\\nproduced\\ndepends\\non\\nonly\\na\\nsubset\\nof\\nthe\\ntraining\\ndata\\nnear\\nthe\\nclass\\nboundaries.\\nSimilarly,\\nthe\\nmodel\\nproduced\\nby\\nSupport\\nVector\\nRegres-\\nsion\\nignores\\nany\\ntraining\\ndata\\nthat\\nis\\nsufficiently\\nclose\\nto\\nthe\\nmodel\\nprediction.\\nSVMs\\nare\\nalso\\nsaid\\nto\\nbelong\\nto\\n“kernel\\nmethods”.\\n\\nIn\\naddition\\nto\\nits\\nsolid\\nmathematical\\nfoundation\\nin\\nstatistical\\nlearning\\ntheory,\\nSVMs\\nhave\\ndemonstrated\\nhighly\\ncompetitive\\nperformance\\nin\\nnumerous\\nreal-world\\napplications,\\nsuch\\nas\\nbioinformatics,\\ntext\\nmining,\\nface\\nrecognition,\\nand\\nimage\\nprocessing,\\nwhich\\nhas\\nestablished\\nSVMs\\nas\\none\\nof\\nthe\\nstate-of-\\nthe-art\\ntools\\nfor\\nmachine\\nlearning\\nand\\ndata\\nmining,\\nalong\\nwith\\nother\\nsoft\\ncomputing\\ntechniques,\\ne.g.,\\nneural\\nnetworks\\nand\\nfuzzy\\nsystems.\\n\\nThis\\nvolume\\nis\\ncomposed\\nof\\n20\\nchapters\\nselected\\nfrom\\nthe\\nrecent\\nmyriad\\nof\\nnovel\\nSVM\\napplications,\\npowerful\\nSVM\\nalgorithms,\\nas\\nwell\\nas\\nenlighten-\\ning\\ntheoretical\\nanalysis.\\nWritten\\nby\\nexperts\\nin\\ntheir\\nrespective\\nfields,\\nthe\\nfirst\\n12\\nchapters\\nconcentrate\\non\\nSVM\\ntheory,\\nwhereas\\nthe\\nsubsequent\\n8\\nchapters\\nemphasize\\npractical\\napplications,\\nalthough\\nthe\\n“decision\\nboundary”\\nseparat-\\ning\\nthese\\ntwo\\ncategories\\nis\\nrather\\n“fuzzy”.\\n\\nKecman\\nfirst\\npresents\\nan\\nintroduction\\non\\nthe\\nSVM,\\nexplaining\\nthe\\nbasic\\ntheory\\nand\\nimplementation\\naspects.\\nIn\\nthe\\nchapter\\ncontributed\\nby\\nMa\\nand\\nCherkassky,\\na\\nnovel\\napproach\\nto\\nnonlinear\\nclassification\\nusing\\na\\ncollection\\nof\\nseveral\\nsimple\\n(linear)\\nclassifiers\\nis\\nproposed\\nbased\\non\\na\\nnew\\nformulation\\nof\\nthe\\nlearning\\nproblem\\ncalled\\nmultiple\\nmodel\\nestimation.\\nPelckmans,\\nGoethals,\\nDe\\nBrabanter,\\nSuykens,\\nand\\nDe\\nMoor\\ndescribe\\ncomponentwise\\nLeast\\nSquares\\nSupport\\nVector\\nMachines\\n(LS-SVMs)\\nfor\\nthe\\nestimation\\nof\\nadditive\\nmodels\\nconsisting\\nof\\na\\nsum\\nof\\nnonlinear\\ncomponents.\\n'\n",
       "3. 'VI\\nPreface\\n\\nMotivated\\nby\\nthe\\nstatistical\\nquery\\nmodel,\\nMitra,\\nMurthy\\nand\\nPal\\nstudy\\nan\\nactive\\nlearning\\nstrategy\\nto\\nsolve\\nthe\\nlarge\\nquadratic\\nprogramming\\nproblem\\nof\\nSVM\\ndesign\\nin\\ndata\\nmining\\napplications.\\nKaizhu\\nHuang,\\nHaiqin\\nYang,\\nKing,\\nand\\nLyu\\npropose\\na\\nunifying\\ntheory\\nof\\nthe\\nMaxi-Min\\nMargin\\nMachine\\n(M4)\\nthat\\nsubsumes\\nthe\\nSVM,\\nthe\\nminimax\\nprobability\\nmachine,\\nand\\nthe\\nlinear\\ndiscriminant\\nanalysis.\\nVogt\\nand\\nKecman\\npresent\\nan\\nactive-set\\nalgorithm\\nfor\\nquadratic\\nprogramming\\nproblems\\nin\\nSVMs,\\nas\\nan\\nalternative\\nto\\nworking-set\\n(decomposition)\\ntechniques,\\nespecially\\nwhen\\nthe\\ndata\\nset\\nis\\nnot\\ntoo\\nlarge,\\nthe\\nproblem\\nis\\nill-conditioned,\\nor\\nwhen\\nhigh\\nprecision\\nis\\nneeded.\\n\\nBeing\\naware\\nof\\nthe\\nabundance\\nof\\nmethods\\nfor\\nSVM\\nmodel\\nselection,\\nAnguita,\\nBoni,\\nRidella,\\nRivieccio,\\nand\\nSterpi\\ncarefully\\nanalyze\\nthe\\nmost\\nwell-\\nknown\\nmethods\\nand\\ntest\\nsome\\nof\\nthem\\non\\nstandard\\nbenchmarks\\nto\\nevaluate\\ntheir\\neffectiveness.\\nIn\\nan\\nattempt\\nto\\nminimize\\nbias,\\nPeng,\\nHeisterkamp,\\nand\\nDai\\npropose\\nlocally\\nadaptive\\nnearest\\nneighbor\\nclassification\\nmethods\\nby\\nusing\\nlocally\\nlinear\\nSVMs\\nand\\nquasiconformal\\ntransformed\\nkernels.\\nWilliams,\\nWu,\\nand\\nFeng\\ndiscuss\\ntwo\\ngeometric\\nmethods\\nto\\nimprove\\nSVM\\nperformance,\\ni.e.,\\n(1)\\nadapting\\nkernels\\nby\\nmagnifying\\nthe\\nRiemannian\\nmetric\\nin\\nthe\\nneighbor-\\nhood\\nof\\nthe\\nboundary,\\nthereby\\nincreasing\\nclass\\nseparation,\\nand\\n(2)\\noptimally\\nlocating\\nthe\\nseparating\\nboundary,\\ngiven\\nthat\\nthe\\ndistributions\\nof\\ndata\\non\\neither\\nside\\nmay\\nhave\\ndifferent\\nscales.\\n\\nSong,\\nHu,\\nand\\nXulei\\nYang\\nderive\\na\\nKuhn-Tucker\\ncondition\\nand\\na\\ndecom-\\nposition\\nalgorithm\\nfor\\nrobust\\nSVMs\\nto\\ndeal\\nwith\\noverfitting\\nin\\nthe\\npresence\\nof\\noutliers.\\nLin\\nand\\nSheng-de\\nWang\\ndesign\\na\\nfuzzy\\nSVM\\nwith\\nautomatic\\ndeter-\\nmination\\nof\\nthe\\nmembership\\nfunctions.\\nKecman,\\nTe-Ming\\nHuang,\\nand\\nVogt\\npresent\\nthe\\nlatest\\ndevelopments\\nand\\nresults\\nof\\nthe\\nIterative\\nSingle\\nData\\nAlgo-\\nrithm\\nfor\\nsolving\\nlarge-scale\\nproblems.\\n\\nExploiting\\nregularization\\nand\\nsubspace\\ndecomposition\\ntechniques,\\nLu,\\nPlataniotis,\\nand\\nVenetsanopoulos\\nintroduce\\na\\nnew\\nkernel\\ndiscriminant\\nlearn-\\ning\\nmethod\\nand\\napply\\nthe\\nmethod\\nto\\nface\\nrecognition.\\nKwang\\nIn\\nKim,\\nJung,\\nand\\nHang\\nJoon\\nKim\\nemploy\\nSVMs\\nand\\nneural\\nnetworks\\nfor\\nautomobile\\nli-\\ncense\\nplate\\nlocalization,\\nby\\nclassifying\\neach\\npixel\\nin\\nthe\\nimage\\ninto\\nthe\\nobject\\nof\\ninterest\\nor\\nthe\\nbackground\\nbased\\non\\nlocalized\\ncolor\\ntexture\\npatterns.\\nMat-\\ntera\\ndiscusses\\nSVM\\napplications\\nin\\nsignal\\nprocessing,\\nespecially\\nthe\\nproblem\\nof\\ndigital\\nchannel\\nequalization.\\nChu,\\nJin,\\nand\\nLipo\\nWang\\nuse\\nSVMs\\nto\\nsolve\\ntwo\\nimportant\\nproblems\\nin\\nbioinformatics,\\ni.e.,\\ncancer\\ndiagnosis\\nbased\\non\\nmi-\\ncroarray\\ngene\\nexpression\\ndata\\nand\\nprotein\\nsecondary\\nstructure\\nprediction.\\n\\nEmulating\\nthe\\nnatural\\nnose,\\nBrezmes,\\nLlobet,\\nAl-Khalifa,\\nMaldonado,\\nand\\nGardner\\ndescribe\\nhow\\nSVMs\\nare\\nbeing\\nevaluated\\nin\\nthe\\ngas\\nsensor\\ncommu-\\nnity\\nto\\ndiscriminate\\ndifferent\\nblends\\nof\\ncoffee,\\ndifferent\\ntypes\\nof\\nvapors\\nand\\nnerve\\nagents.\\nZhan\\npresents\\nan\\napplication\\nof\\nthe\\nSVM\\nin\\ninverse\\nproblems\\nin\\nocean\\ncolor\\nremote\\nsensing.\\nLiang\\nuses\\nSVMs\\nfor\\nnon-invasive\\ndiagnosis\\nof\\ndelayed\\ngastric\\nemptying\\nfrom\\nthe\\ncutaneous\\nelectrogastrograms\\n(EGGs).\\nRojo-Alvarez,\\nGarcia-Alberola,\\nArtés-Rodriguez,\\nand\\nArenal-Maiz\\napply\\nSVMs,\\ntogether\\nwith\\nbootstrap\\nresampling\\nand\\nprincipal\\ncomponent\\nanalysis,\\nto\\ntachycardia\\ndiscrimination\\nin\\nimplantable\\ncardioverter\\ndefibrillators.\\n'\n",
       "4. 'Preface\\nVil\\nI\\nwould\\nlike\\nto\\nexpress\\nmy\\nsincere\\nappreciation\\nto\\nall\\nauthors\\nand\\nreviewers\\nwho\\nhave\\nspent\\ntheir\\nprecious\\ntime\\nand\\nefforts\\nin\\nmaking\\nthis\\nbook\\na\\nreality.\\nI\\nwish\\nto\\nespecially\\nthank\\nProfessor\\nVojislav\\nKecman,\\nwho\\ngraciously\\ntook\\non\\nthe\\nenormous\\ntask\\nof\\nwriting\\na\\ncomprehensive\\nintroductory\\nchapter,\\nin\\naddition\\nto\\nhis\\nother\\ngreat\\ncontributions\\nto\\nthis\\nbook.\\nMy\\ngratitude\\nalso\\ngoes\\nto\\nProfessor\\nJanusz\\nKacprzyk\\nand\\nDr.\\nThomas\\nDitzinger\\nfor\\ntheir\\nkindest\\nsupport\\nand\\nhelp\\nwith\\nthis\\nbook.\\nSingapore\\nLipo\\nWang\\nJanuary\\n2005\\n'\n",
       "5. ''\n",
       "6. 'Contents\\n\\nSupport\\nVector\\nMachines\\n—\\nAn\\nIntroduction\\n\\nV.\\nK€CMGN.\\n6.\\neee\\neee\\neee\\neee\\neeeeeee\\nMultiple\\nModel\\nEstimation\\n\\nfor\\nNonlinear\\nClassification\\n\\nY.\\nMa\\nand\\nV.\\nCherkassky\\n..\\n0.0.00.\\nAY\\nComponentwise\\nLeast\\nSquares\\nSupport\\nVector\\nMachines\\n\\nKk.\\nPelckmans,\\nI.\\nGoethals,\\nJ.\\nDe\\nBrabanter,\\nJ.A.K.\\nSuykens,\\nand\\nB.\\n\\nDe\\nMOor\\n..\\nccc\\nnee\\neee\\neee\\neee\\nTT\\nActive\\nSupport\\nVector\\nLearning\\nwith\\nStatistical\\nQueries\\n\\nP.\\nMitra,\\nC.A.\\nMurthy,\\nand\\nSK.\\nPal...\\neee\\nee\\nID\\nLocal\\nLearning\\nvs.\\nGlobal\\nLearning:\\nAn\\nIntroduction\\n\\nto\\nMaxi-Min\\nMargin\\nMachine\\n\\nKk.\\nHuang,\\nH.\\nYang,\\nI.\\nKing,\\nand\\nM.R.\\nLyu\\n.....\\neee\\neee\\nee\\nee\\nL18\\nActive-Set\\nMethods\\nfor\\nSupport\\nVector\\nMachines\\n\\nM.\\nVogt\\nand\\nV.\\nKecman\\n...\\n6...\\ncece\\nee\\neee\\nee\\nA\\n138\\nTheoretical\\nand\\nPractical\\nModel\\nSelection\\nMethods\\n\\nfor\\nSupport\\nVector\\nClassifiers\\n\\nD.\\nAnguita,\\nA.\\nBoni,\\nS.\\nRidella,\\nFP.\\nRivieccio,\\nand\\nD.\\nSterpi...........159\\nAdaptive\\nDiscriminant\\n\\nand\\nQuasiconformal\\nKernel\\nNearest\\nNeighbor\\nClassification\\n\\nJ.\\nPeng,\\nD.R.\\nHeisterkamp,\\nand\\nH.K.\\nDat\\n..\\n1...\\nee\\nee\\nLB\\nImproving\\nthe\\nPerformance\\nof\\nthe\\nSupport\\nVector\\nMachine:\\n\\nTwo\\nGeometrical\\nScaling\\nMethods\\n\\nP.\\nWilliams,\\nS.\\nWu,\\nand\\nJ.\\nFeng\\n0.0...\\nccc\\ncee\\neee\\nee\\n205\\n'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"Support\\nVector\\nMachines:\\nTheory\\nand\\nApplications\\nLipo\\nWang\\n(ed.)\\n\\nSpringer,\\nBerlin\\n2005\\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  \n",
       "[2] \"Preface\\n\\nThe\\nsupport\\nvector\\nmachine\\n(SVM)\\nis\\na\\nsupervised\\nlearning\\nmethod\\nthat\\ngenerates\\ninput-output\\nmapping\\nfunctions\\nfrom\\na\\nset\\nof\\nlabeled\\ntraining\\ndata.\\nThe\\nmapping\\nfunction\\ncan\\nbe\\neither\\na\\nclassification\\nfunction,\\ni.e.,\\nthe\\ncate-\\ngory\\nof\\nthe\\ninput\\ndata,\\nor\\na\\nregression\\nfunction.\\nFor\\nclassification,\\nnonlinear\\nkernel\\nfunctions\\nare\\noften\\nused\\nto\\ntransform\\ninput\\ndata\\nto\\na\\nhigh-dimensional\\nfeature\\nspace\\nin\\nwhich\\nthe\\ninput\\ndata\\nbecome\\nmore\\nseparable\\ncompared\\nto\\nthe\\noriginal\\ninput\\nspace.\\nMaximum-margin\\nhyperplanes\\nare\\nthen\\ncreated.\\n‘The\\nmodel\\nthus\\nproduced\\ndepends\\non\\nonly\\na\\nsubset\\nof\\nthe\\ntraining\\ndata\\nnear\\nthe\\nclass\\nboundaries.\\nSimilarly,\\nthe\\nmodel\\nproduced\\nby\\nSupport\\nVector\\nRegres-\\nsion\\nignores\\nany\\ntraining\\ndata\\nthat\\nis\\nsufficiently\\nclose\\nto\\nthe\\nmodel\\nprediction.\\nSVMs\\nare\\nalso\\nsaid\\nto\\nbelong\\nto\\n“kernel\\nmethods”.\\n\\nIn\\naddition\\nto\\nits\\nsolid\\nmathematical\\nfoundation\\nin\\nstatistical\\nlearning\\ntheory,\\nSVMs\\nhave\\ndemonstrated\\nhighly\\ncompetitive\\nperformance\\nin\\nnumerous\\nreal-world\\napplications,\\nsuch\\nas\\nbioinformatics,\\ntext\\nmining,\\nface\\nrecognition,\\nand\\nimage\\nprocessing,\\nwhich\\nhas\\nestablished\\nSVMs\\nas\\none\\nof\\nthe\\nstate-of-\\nthe-art\\ntools\\nfor\\nmachine\\nlearning\\nand\\ndata\\nmining,\\nalong\\nwith\\nother\\nsoft\\ncomputing\\ntechniques,\\ne.g.,\\nneural\\nnetworks\\nand\\nfuzzy\\nsystems.\\n\\nThis\\nvolume\\nis\\ncomposed\\nof\\n20\\nchapters\\nselected\\nfrom\\nthe\\nrecent\\nmyriad\\nof\\nnovel\\nSVM\\napplications,\\npowerful\\nSVM\\nalgorithms,\\nas\\nwell\\nas\\nenlighten-\\ning\\ntheoretical\\nanalysis.\\nWritten\\nby\\nexperts\\nin\\ntheir\\nrespective\\nfields,\\nthe\\nfirst\\n12\\nchapters\\nconcentrate\\non\\nSVM\\ntheory,\\nwhereas\\nthe\\nsubsequent\\n8\\nchapters\\nemphasize\\npractical\\napplications,\\nalthough\\nthe\\n“decision\\nboundary”\\nseparat-\\ning\\nthese\\ntwo\\ncategories\\nis\\nrather\\n“fuzzy”.\\n\\nKecman\\nfirst\\npresents\\nan\\nintroduction\\non\\nthe\\nSVM,\\nexplaining\\nthe\\nbasic\\ntheory\\nand\\nimplementation\\naspects.\\nIn\\nthe\\nchapter\\ncontributed\\nby\\nMa\\nand\\nCherkassky,\\na\\nnovel\\napproach\\nto\\nnonlinear\\nclassification\\nusing\\na\\ncollection\\nof\\nseveral\\nsimple\\n(linear)\\nclassifiers\\nis\\nproposed\\nbased\\non\\na\\nnew\\nformulation\\nof\\nthe\\nlearning\\nproblem\\ncalled\\nmultiple\\nmodel\\nestimation.\\nPelckmans,\\nGoethals,\\nDe\\nBrabanter,\\nSuykens,\\nand\\nDe\\nMoor\\ndescribe\\ncomponentwise\\nLeast\\nSquares\\nSupport\\nVector\\nMachines\\n(LS-SVMs)\\nfor\\nthe\\nestimation\\nof\\nadditive\\nmodels\\nconsisting\\nof\\na\\nsum\\nof\\nnonlinear\\ncomponents.\\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
       "[3] \"VI\\nPreface\\n\\nMotivated\\nby\\nthe\\nstatistical\\nquery\\nmodel,\\nMitra,\\nMurthy\\nand\\nPal\\nstudy\\nan\\nactive\\nlearning\\nstrategy\\nto\\nsolve\\nthe\\nlarge\\nquadratic\\nprogramming\\nproblem\\nof\\nSVM\\ndesign\\nin\\ndata\\nmining\\napplications.\\nKaizhu\\nHuang,\\nHaiqin\\nYang,\\nKing,\\nand\\nLyu\\npropose\\na\\nunifying\\ntheory\\nof\\nthe\\nMaxi-Min\\nMargin\\nMachine\\n(M4)\\nthat\\nsubsumes\\nthe\\nSVM,\\nthe\\nminimax\\nprobability\\nmachine,\\nand\\nthe\\nlinear\\ndiscriminant\\nanalysis.\\nVogt\\nand\\nKecman\\npresent\\nan\\nactive-set\\nalgorithm\\nfor\\nquadratic\\nprogramming\\nproblems\\nin\\nSVMs,\\nas\\nan\\nalternative\\nto\\nworking-set\\n(decomposition)\\ntechniques,\\nespecially\\nwhen\\nthe\\ndata\\nset\\nis\\nnot\\ntoo\\nlarge,\\nthe\\nproblem\\nis\\nill-conditioned,\\nor\\nwhen\\nhigh\\nprecision\\nis\\nneeded.\\n\\nBeing\\naware\\nof\\nthe\\nabundance\\nof\\nmethods\\nfor\\nSVM\\nmodel\\nselection,\\nAnguita,\\nBoni,\\nRidella,\\nRivieccio,\\nand\\nSterpi\\ncarefully\\nanalyze\\nthe\\nmost\\nwell-\\nknown\\nmethods\\nand\\ntest\\nsome\\nof\\nthem\\non\\nstandard\\nbenchmarks\\nto\\nevaluate\\ntheir\\neffectiveness.\\nIn\\nan\\nattempt\\nto\\nminimize\\nbias,\\nPeng,\\nHeisterkamp,\\nand\\nDai\\npropose\\nlocally\\nadaptive\\nnearest\\nneighbor\\nclassification\\nmethods\\nby\\nusing\\nlocally\\nlinear\\nSVMs\\nand\\nquasiconformal\\ntransformed\\nkernels.\\nWilliams,\\nWu,\\nand\\nFeng\\ndiscuss\\ntwo\\ngeometric\\nmethods\\nto\\nimprove\\nSVM\\nperformance,\\ni.e.,\\n(1)\\nadapting\\nkernels\\nby\\nmagnifying\\nthe\\nRiemannian\\nmetric\\nin\\nthe\\nneighbor-\\nhood\\nof\\nthe\\nboundary,\\nthereby\\nincreasing\\nclass\\nseparation,\\nand\\n(2)\\noptimally\\nlocating\\nthe\\nseparating\\nboundary,\\ngiven\\nthat\\nthe\\ndistributions\\nof\\ndata\\non\\neither\\nside\\nmay\\nhave\\ndifferent\\nscales.\\n\\nSong,\\nHu,\\nand\\nXulei\\nYang\\nderive\\na\\nKuhn-Tucker\\ncondition\\nand\\na\\ndecom-\\nposition\\nalgorithm\\nfor\\nrobust\\nSVMs\\nto\\ndeal\\nwith\\noverfitting\\nin\\nthe\\npresence\\nof\\noutliers.\\nLin\\nand\\nSheng-de\\nWang\\ndesign\\na\\nfuzzy\\nSVM\\nwith\\nautomatic\\ndeter-\\nmination\\nof\\nthe\\nmembership\\nfunctions.\\nKecman,\\nTe-Ming\\nHuang,\\nand\\nVogt\\npresent\\nthe\\nlatest\\ndevelopments\\nand\\nresults\\nof\\nthe\\nIterative\\nSingle\\nData\\nAlgo-\\nrithm\\nfor\\nsolving\\nlarge-scale\\nproblems.\\n\\nExploiting\\nregularization\\nand\\nsubspace\\ndecomposition\\ntechniques,\\nLu,\\nPlataniotis,\\nand\\nVenetsanopoulos\\nintroduce\\na\\nnew\\nkernel\\ndiscriminant\\nlearn-\\ning\\nmethod\\nand\\napply\\nthe\\nmethod\\nto\\nface\\nrecognition.\\nKwang\\nIn\\nKim,\\nJung,\\nand\\nHang\\nJoon\\nKim\\nemploy\\nSVMs\\nand\\nneural\\nnetworks\\nfor\\nautomobile\\nli-\\ncense\\nplate\\nlocalization,\\nby\\nclassifying\\neach\\npixel\\nin\\nthe\\nimage\\ninto\\nthe\\nobject\\nof\\ninterest\\nor\\nthe\\nbackground\\nbased\\non\\nlocalized\\ncolor\\ntexture\\npatterns.\\nMat-\\ntera\\ndiscusses\\nSVM\\napplications\\nin\\nsignal\\nprocessing,\\nespecially\\nthe\\nproblem\\nof\\ndigital\\nchannel\\nequalization.\\nChu,\\nJin,\\nand\\nLipo\\nWang\\nuse\\nSVMs\\nto\\nsolve\\ntwo\\nimportant\\nproblems\\nin\\nbioinformatics,\\ni.e.,\\ncancer\\ndiagnosis\\nbased\\non\\nmi-\\ncroarray\\ngene\\nexpression\\ndata\\nand\\nprotein\\nsecondary\\nstructure\\nprediction.\\n\\nEmulating\\nthe\\nnatural\\nnose,\\nBrezmes,\\nLlobet,\\nAl-Khalifa,\\nMaldonado,\\nand\\nGardner\\ndescribe\\nhow\\nSVMs\\nare\\nbeing\\nevaluated\\nin\\nthe\\ngas\\nsensor\\ncommu-\\nnity\\nto\\ndiscriminate\\ndifferent\\nblends\\nof\\ncoffee,\\ndifferent\\ntypes\\nof\\nvapors\\nand\\nnerve\\nagents.\\nZhan\\npresents\\nan\\napplication\\nof\\nthe\\nSVM\\nin\\ninverse\\nproblems\\nin\\nocean\\ncolor\\nremote\\nsensing.\\nLiang\\nuses\\nSVMs\\nfor\\nnon-invasive\\ndiagnosis\\nof\\ndelayed\\ngastric\\nemptying\\nfrom\\nthe\\ncutaneous\\nelectrogastrograms\\n(EGGs).\\nRojo-Alvarez,\\nGarcia-Alberola,\\nArtés-Rodriguez,\\nand\\nArenal-Maiz\\napply\\nSVMs,\\ntogether\\nwith\\nbootstrap\\nresampling\\nand\\nprincipal\\ncomponent\\nanalysis,\\nto\\ntachycardia\\ndiscrimination\\nin\\nimplantable\\ncardioverter\\ndefibrillators.\\n\"\n",
       "[4] \"Preface\\nVil\\nI\\nwould\\nlike\\nto\\nexpress\\nmy\\nsincere\\nappreciation\\nto\\nall\\nauthors\\nand\\nreviewers\\nwho\\nhave\\nspent\\ntheir\\nprecious\\ntime\\nand\\nefforts\\nin\\nmaking\\nthis\\nbook\\na\\nreality.\\nI\\nwish\\nto\\nespecially\\nthank\\nProfessor\\nVojislav\\nKecman,\\nwho\\ngraciously\\ntook\\non\\nthe\\nenormous\\ntask\\nof\\nwriting\\na\\ncomprehensive\\nintroductory\\nchapter,\\nin\\naddition\\nto\\nhis\\nother\\ngreat\\ncontributions\\nto\\nthis\\nbook.\\nMy\\ngratitude\\nalso\\ngoes\\nto\\nProfessor\\nJanusz\\nKacprzyk\\nand\\nDr.\\nThomas\\nDitzinger\\nfor\\ntheir\\nkindest\\nsupport\\nand\\nhelp\\nwith\\nthis\\nbook.\\nSingapore\\nLipo\\nWang\\nJanuary\\n2005\\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              \n",
       "[5] \"\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \n",
       "[6] \"Contents\\n\\nSupport\\nVector\\nMachines\\n—\\nAn\\nIntroduction\\n\\nV.\\nK\\200CMGN.\\n6.\\neee\\neee\\neee\\neee\\neeeeeee\\nMultiple\\nModel\\nEstimation\\n\\nfor\\nNonlinear\\nClassification\\n\\nY.\\nMa\\nand\\nV.\\nCherkassky\\n..\\n0.0.00.\\nAY\\nComponentwise\\nLeast\\nSquares\\nSupport\\nVector\\nMachines\\n\\nKk.\\nPelckmans,\\nI.\\nGoethals,\\nJ.\\nDe\\nBrabanter,\\nJ.A.K.\\nSuykens,\\nand\\nB.\\n\\nDe\\nMOor\\n..\\nccc\\nnee\\neee\\neee\\neee\\nTT\\nActive\\nSupport\\nVector\\nLearning\\nwith\\nStatistical\\nQueries\\n\\nP.\\nMitra,\\nC.A.\\nMurthy,\\nand\\nSK.\\nPal...\\neee\\nee\\nID\\nLocal\\nLearning\\nvs.\\nGlobal\\nLearning:\\nAn\\nIntroduction\\n\\nto\\nMaxi-Min\\nMargin\\nMachine\\n\\nKk.\\nHuang,\\nH.\\nYang,\\nI.\\nKing,\\nand\\nM.R.\\nLyu\\n.....\\neee\\neee\\nee\\nee\\nL18\\nActive-Set\\nMethods\\nfor\\nSupport\\nVector\\nMachines\\n\\nM.\\nVogt\\nand\\nV.\\nKecman\\n...\\n6...\\ncece\\nee\\neee\\nee\\nA\\n138\\nTheoretical\\nand\\nPractical\\nModel\\nSelection\\nMethods\\n\\nfor\\nSupport\\nVector\\nClassifiers\\n\\nD.\\nAnguita,\\nA.\\nBoni,\\nS.\\nRidella,\\nFP.\\nRivieccio,\\nand\\nD.\\nSterpi...........159\\nAdaptive\\nDiscriminant\\n\\nand\\nQuasiconformal\\nKernel\\nNearest\\nNeighbor\\nClassification\\n\\nJ.\\nPeng,\\nD.R.\\nHeisterkamp,\\nand\\nH.K.\\nDat\\n..\\n1...\\nee\\nee\\nLB\\nImproving\\nthe\\nPerformance\\nof\\nthe\\nSupport\\nVector\\nMachine:\\n\\nTwo\\nGeometrical\\nScaling\\nMethods\\n\\nP.\\nWilliams,\\nS.\\nWu,\\nand\\nJ.\\nFeng\\n0.0...\\nccc\\ncee\\neee\\nee\\n205\\n\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#separation of each word as separate record\n",
    "textnew<-str_replace_all(text,\"\\n\",\" \")\n",
    "textnew1<-str_replace_all(textnew,\" \", \"\\n\")\n",
    "  \n",
    "head(textnew1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file as .csv\n",
    "fileConn<- file(\"M:\\\\Imarticus\\\\data sets\\\\Text mining\\\\tsvm9.csv\")\n",
    "writeLines(textnew1,fileConn)\n",
    "close(fileConn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
